<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Mac上如何使用SSH连接到GitHub</title>
      <link href="/2019/05/26/Mac%E4%B8%8A%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8SSH%E8%BF%9E%E6%8E%A5%E5%88%B0GitHub/"/>
      <url>/2019/05/26/Mac%E4%B8%8A%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8SSH%E8%BF%9E%E6%8E%A5%E5%88%B0GitHub/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><h2 id="关于SSH"><a href="#关于SSH" class="headerlink" title="关于SSH"></a>关于SSH</h2><p>使用SSH协议，你可以连接和验证远程服务器与服务。 使用SSH密钥，你可以在每次访问时<strong>不提供</strong>用户名或密码就可以连接到GitHub，即免密登陆。</p><p>当你设置SSH时，你需要生成SSH密钥并将其添加到ssh-agent，然后将密钥添加到您的GitHub帐户。 将SSH密钥添加到ssh-agent可确保你的SSH密钥通过使用passphrase而具有额外的安全层。</p><p>如果你超过一年未使用SSH密钥，那么根据安全预防措施，GitHub将自动删除你的非活动SSH密钥。</p><h2 id="检查现有的SSH密钥"><a href="#检查现有的SSH密钥" class="headerlink" title="检查现有的SSH密钥"></a>检查现有的SSH密钥</h2><p>在生成SSH密钥之前，你可以检查是否已经有SSH密钥存在。</p><blockquote><p>注意：在OpenSSH 7.0中不推荐使用DSA密钥。 如果你的操作系统使用OpenSSH，则在设置SSH时需要使用备用类型的密钥，例如RSA密钥。 例如，如果你的操作系统是MacOS Sierra，则可以使用RSA密钥设置SSH。</p></blockquote><ol><li>打开终端 </li><li><p>输入ls -al ~/.ssh以查看是否存在现有SSH密钥：</p> <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> ls -al ~/.ssh</span><br><span class="line"><span class="meta">#</span> Lists the files in your .ssh directory, if they exist</span><br></pre></td></tr></table></figure></li><li><p>检查目录列表以查看你是否已拥有公共SSH密钥。</p></li></ol><p>默认情况下，公钥的文件名是以下之一：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">id_dsa.pub</span><br><span class="line">id_ecdsa.pub</span><br><span class="line">id_ed25519.pub</span><br><span class="line">id_rsa.pub</span><br></pre></td></tr></table></figure></p><ul><li>如你没有现有的公钥和私钥对，或者不希望使用任何可用的连接到GitHub，则生成新的SSH密钥。</li><li>如果你看到要用于连接到GitHub的现有公钥和私钥对（例如id_rsa.pub和id_rsa），则可以将SSH密钥添加到ssh-agent。</li></ul><blockquote><p>提示：如果收到~/.ssh不存在的错误，请不要担心！ 我们可以通过指令生成新的SSH密钥。</p></blockquote><h2 id="生成新的SSH密钥并将其添加到ssh-agent"><a href="#生成新的SSH密钥并将其添加到ssh-agent" class="headerlink" title="生成新的SSH密钥并将其添加到ssh-agent"></a>生成新的SSH密钥并将其添加到ssh-agent</h2><p>检查现有SSH密钥后，可以生成用于身份验证的新SSH密钥，然后将其添加到ssh-agent。</p><p>如果你还没有SSH密钥，则必须生成新的SSH密钥。如果你不确定是否已有SSH密钥，请检查现有密钥。</p><p>如果你不想在每次使用SSH密钥时重新输入密码，则可以将密钥添加到ssh-agent，ssh-agent管理你的SSH密钥并记住你的密码。</p><h3 id="生成新的SSH密钥"><a href="#生成新的SSH密钥" class="headerlink" title="生成新的SSH密钥"></a>生成新的SSH密钥</h3><ol><li><p>打开终端 </p></li><li><p>在终端粘贴下面的文本，记得替换你自己的GitHub电子邮件地址。</p> <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> ssh-keygen -t rsa -b 4096 -C“your_email@example.com”</span><br></pre></td></tr></table></figure><p> 这将使用你提供的电子邮件作为标签创建一个新的ssh密钥。</p> <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span> Generating public/private rsa key pair.</span><br></pre></td></tr></table></figure></li><li><p>当系统提你 “Enter a file in which to save the key”时，按Enter键。这将使用默认的文件位置。</p> <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span>Enter a file in which to save the key (/Users/you/.ssh/id_rsa): [Press enter]</span><br></pre></td></tr></table></figure></li><li><p>在提示符下，键入安全密码。</p> <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span> Enter passphrase (empty for no passphrase): [Type a passphrase]</span><br><span class="line"><span class="meta">&gt;</span> Enter same passphrase again: [Type passphrase again]</span><br></pre></td></tr></table></figure></li></ol><h3 id="将SSH密钥添加到ssh-agent"><a href="#将SSH密钥添加到ssh-agent" class="headerlink" title="将SSH密钥添加到ssh-agent"></a>将SSH密钥添加到ssh-agent</h3><p>在将新的SSH密钥添加到ssh-agent以管理密钥之前，你应该检查现有的SSH密钥并生成新的SSH密钥。将SSH密钥添加到代理时，请使用默认的macOS ssh-add命令，而不是macports，homebrew或其他外部源安装的应用程序。</p><ol><li><p>在后台启动ssh-agent。</p> <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> eval "$(ssh-agent -s)"</span><br><span class="line"><span class="meta">&gt;</span> Agent pid 59566</span><br></pre></td></tr></table></figure></li><li><p>如果你使用的是macOS Sierra 10.12.2或更高版本，则需要修改 <strong>~/.ssh/config</strong>文件以自动将密钥加载到ssh-agent中并在密钥链中存储密码。</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Host *</span><br><span class="line">  AddKeysToAgent yes</span><br><span class="line">  UseKeychain yes</span><br><span class="line">  IdentityFile ~/.ssh/id_rsa</span><br></pre></td></tr></table></figure></li><li><p>将SSH私钥添加到ssh-agent并将密码存储在密钥链中。如果使用其他名称创建密钥，或者要添加具有不同名称的现有密钥，请将命令中的id_rsa替换为私钥文件的名称。</p> <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> ssh-add -K ~/.ssh/id_rsa</span><br></pre></td></tr></table></figure></li></ol><blockquote><p>注意：-K选项是Apple的ssh-add标准版本，当您向ssh-agent添加ssh密钥时，它会将密码链存储在你的钥匙串中。如果你没有安装Apple的标准版本，则可能会收到错误消息 Error: ssh-add: illegal option -- K.。</p></blockquote><ol start="4"><li>将SSH密钥添加到GitHub帐户（看下一步）</li></ol><h3 id="将新SSH密钥添加到GitHub帐户"><a href="#将新SSH密钥添加到GitHub帐户" class="headerlink" title="将新SSH密钥添加到GitHub帐户"></a>将新SSH密钥添加到GitHub帐户</h3><p>要将GitHub帐户配置为使用新的(或现有的)SSH密钥，你还需要将其添加到GitHub帐户。具体步骤请参考<a href="https://help.github.com/en/articles/adding-a-new-ssh-key-to-your-github-account" target="_blank" rel="noopener">官网文档</a></p><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>在设置SSH密钥并将其添加到GitHub帐户后，你可以测试你的连接是否成功。在测试SSH连接之前，你应该：</p><ul><li>检查现有SSH密钥</li><li>生成新的SSH密钥</li><li>为你的GitHub帐户添加了新的SSH密钥</li></ul><p>测试连接时，你需要使用密码验证此操作，密码是你之前创建的SSH密钥密码。有关使用SSH密钥密码的更多信息，请参阅<a href="https://help.github.com/en/articles/working-with-ssh-key-passphrases" target="_blank" rel="noopener">“使用SSH密钥密码”</a>。</p><ol><li>打开终端</li><li><p>输入以下内容：</p> <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> ssh -T git@github.com</span><br><span class="line"><span class="meta">#</span> Attempts to ssh to GitHub</span><br></pre></td></tr></table></figure><p> 你可能会看到如下警告：</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt; The authenticity of host &apos;github.com (IP ADDRESS)&apos; can&apos;t be established.</span><br><span class="line">  &gt; RSA key fingerprint is 16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48.</span><br><span class="line">  &gt; Are you sure you want to continue connecting (yes/no)?</span><br></pre></td></tr></table></figure><p> 或者：</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt; The authenticity of host &apos;github.com (IP ADDRESS)&apos; can&apos;t be established.</span><br><span class="line">  &gt; RSA key fingerprint is SHA256:nThbg6kXUpJWGl7E1IGOCspRomTxdCARLviKw6E5SY8.</span><br><span class="line">  &gt; Are you sure you want to continue connecting (yes/no)?</span><br></pre></td></tr></table></figure></li><li><p>验证你看到的消息中的fingerprint是否与步骤2中的某条消息匹配，然后键入yes：</p> <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span> Hi username! You've successfully authenticated, but GitHub does not</span><br><span class="line"><span class="meta">&gt;</span> provide shell access.</span><br></pre></td></tr></table></figure></li><li><p>验证生成的消息是否包含你的用户名。如果收到“permission denied”消息，请参阅<a href="https://help.github.com/en/articles/error-permission-denied-publickey" target="_blank" rel="noopener">&quot;Error: Permission denied (publickey)&quot;</a>。</p></li></ol><h2 id="使用SSH密钥密码"><a href="#使用SSH密钥密码" class="headerlink" title="使用SSH密钥密码"></a>使用SSH密钥密码</h2><p>你可以保护SSH密钥并配置身份验证代理，这样你就不必在每次使用SSH密钥时重新输入密码。</p><p>使用SSH密钥，如果有人获得对你计算机的访问权限，他们也可以访问使用该密钥的每个系统。 要添加额外的安全层，可以向SSH密钥添加密码。 你可以使用ssh-agent安全地保存密码，这样你就不必重新输入密码。</p><h3 id="添加或更改passphrase"><a href="#添加或更改passphrase" class="headerlink" title="添加或更改passphrase"></a>添加或更改passphrase</h3><p>你可以通过键入以下命令来更改现有私钥的密码，而无需重新生成密钥对：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> ssh-keygen -p</span><br><span class="line"><span class="meta">#</span> Start the SSH key creation process</span><br><span class="line"><span class="meta">&gt;</span> Enter file in which the key is (/Users/you/.ssh/id_rsa): [Hit enter]</span><br><span class="line"><span class="meta">&gt;</span> Key has comment '/Users/you/.ssh/id_rsa'</span><br><span class="line"><span class="meta">&gt;</span> Enter new passphrase (empty for no passphrase): [Type new passphrase]</span><br><span class="line"><span class="meta">&gt;</span> Enter same passphrase again: [One more time for luck]</span><br><span class="line"><span class="meta">&gt;</span> Your identification has been saved with the new passphrase.</span><br></pre></td></tr></table></figure><p>如果你的密钥已有passphrase，系统将提示你输入密码短语，然后才能更改为新密码短语。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://help.github.com/en/articles/connecting-to-github-with-ssh" target="_blank" rel="noopener">Connecting to GitHub with SSH</a></p>]]></content>
      
      
      <categories>
          
          <category> Mac </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mac </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>记录下本周末搭建个人博客的过程Mac+Hexo+GitHubPages</title>
      <link href="/2019/05/26/%E8%AE%B0%E5%BD%95%E4%B8%8B%E6%9C%AC%E5%91%A8%E6%9C%AB%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E7%9A%84%E8%BF%87%E7%A8%8BMac+Hexo+GitHubPages/"/>
      <url>/2019/05/26/%E8%AE%B0%E5%BD%95%E4%B8%8B%E6%9C%AC%E5%91%A8%E6%9C%AB%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E7%9A%84%E8%BF%87%E7%A8%8BMac+Hexo+GitHubPages/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>之前本来有一个个人博客，但是因为太懒没有维护，就来投奔CSDN了。这几天突然一时兴起，让好好弄一下自己的个人博客，因为CSDN的广告实在是....一言难尽...搜索了一般，选取一个比较简单的实现方式：即Hexo+GitHub Pages以下记录如果搭建个人博客网站 <a href="https://lestatzhang.com/" target="_blank" rel="noopener">lestatzhang.com</a>的过程</p><h2 id="具体步骤"><a href="#具体步骤" class="headerlink" title="具体步骤"></a>具体步骤</h2><ol><li>安装Git</li><li>安装Node.js</li><li>安装Hexo</li><li>博客初始化</li><li>将本地博客与GitHub关联</li><li>切换Hexo主题：Next</li><li>Goddady购买个人域名</li><li>绑定个人域名</li><li>其他TO-DO</li></ol><h3 id="安装Git"><a href="#安装Git" class="headerlink" title="安装Git"></a>安装Git</h3><p>先查看是否已经安装Git <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lestat@Lestats-MBP:~$ git --version</span><br><span class="line">git version 2.14.3 (Apple Git-98)</span><br></pre></td></tr></table></figure></p><p> 如果Mac没有安装git可以通过Homebrew安装 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew install git</span><br></pre></td></tr></table></figure></p><h3 id="安装Node-js"><a href="#安装Node-js" class="headerlink" title="安装Node.js"></a>安装Node.js</h3><p> 如果Mac没有安装Node.js可以通过Homebrew安装 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew install node</span><br></pre></td></tr></table></figure></p><p>中间有可能因为一些依赖库需要更新你的Xcode的Command Line Tools</p><p>我安装的版本如下：<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">lestat@Lestats-MBP:~$ node -v</span><br><span class="line">v12.3.1</span><br><span class="line">lestat@Lestats-MBP:~$ npm -v</span><br><span class="line">6.9.0</span><br></pre></td></tr></table></figure></p><h3 id="安装Hexo"><a href="#安装Hexo" class="headerlink" title="安装Hexo"></a>安装Hexo</h3><p>Node.js和Git都安装成功后开始安装Hexo<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo npm install -g hexo-cli</span><br></pre></td></tr></table></figure></p><h3 id="博客初始化"><a href="#博客初始化" class="headerlink" title="博客初始化"></a>博客初始化</h3><p>创建你本地的博客文件夹，比如我的就是 lestatzhang， 然后进入该文件夹，利用hexo进行初始化<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd lestatzhang;</span><br><span class="line">hexo init;</span><br></pre></td></tr></table></figure></p><p>执行下述命令安装npm。<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo npm install;</span><br></pre></td></tr></table></figure></p><p>执行hexo命令生成本地网页文件<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo g</span><br></pre></td></tr></table></figure></p><p>执行hexo命令开启本地服务器<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo s</span><br></pre></td></tr></table></figure></p><p>然后我们就通过 <a href="http://localhost:4000" target="_blank" rel="noopener">http://localhost:4000</a> 查看本地博客。</p><h3 id="将本地博客与GitHub关联"><a href="#将本地博客与GitHub关联" class="headerlink" title="将本地博客与GitHub关联"></a>将本地博客与GitHub关联</h3><p>编辑站点配置文件<code>_config.yml</code><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi _config.yml</span><br></pre></td></tr></table></figure></p><p>打开后到文档最后部分，配置deploy设置如下：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">deploy:</span><br><span class="line">  type: git</span><br><span class="line">  repository: https://github.com/lestatzhang/lestatzhang.github.io.git</span><br><span class="line">  branch: master</span><br></pre></td></tr></table></figure></p><p>然后为hexo配置git部署服务：<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure></p><p>运行hexo命令，将在lestatzhang下生成静态文件并上传到git服务器。<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo d</span><br></pre></td></tr></table></figure></p><p>若未关联GitHub，执行hexo d时会提示输入GitHub账号用户名和密码，即:<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">username for 'https://github.com':</span><br><span class="line">password for 'https://github.com':</span><br></pre></td></tr></table></figure></p><p><code>hexo d</code>执行成功后便可通过 <a href="https://lestatzhang.github.io" target="_blank" rel="noopener">https://lestatzhang.github.io</a> 访问博客，看到的内容和本地页面一致。</p><p>如果需要开启ssh，我们可以在Github中配置ssh keys。具体步骤可以参考<a href="https://help.github.com/en/articles/connecting-to-github-with-ssh" target="_blank" rel="noopener">Connecting to GitHub with SSH</a></p><h3 id="切换Hexo主题：Next"><a href="#切换Hexo主题：Next" class="headerlink" title="切换Hexo主题：Next"></a>切换Hexo主题：Next</h3><p>Hexo允许我们为自己的站点配置自己喜欢的主题, 在这里我选择一个个人比较喜欢的主题: <strong>hexo-theme-next</strong>。 安装过程如下：<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd lestatzhang;</span><br><span class="line">git clone https://github.com/iissnan/hexo-theme-next themes/next</span><br></pre></td></tr></table></figure></p><p>编辑站点配置文件_config.yml，将theme的值从landscape更改为next将blog目录下_config.yml里的theme的名称landscape更改为next。</p><p>然后重新生成站点文件,并查看<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hexo g  </span><br><span class="line">hexo s</span><br></pre></td></tr></table></figure></p><h3 id="Godaddy购买个人域名"><a href="#Godaddy购买个人域名" class="headerlink" title="Godaddy购买个人域名"></a>Godaddy购买个人域名</h3><p>在Godday上买了一个自己的域名 <a href="https://lestatzhang.com/" target="_blank" rel="noopener">lestatzhang.com</a></p><h3 id="绑定个人域名"><a href="#绑定个人域名" class="headerlink" title="绑定个人域名"></a>绑定个人域名</h3><p>Godaddy的配置可以参考如下图片<img src="./godadday.png" alt></p><p>然后在next主题中source文件夹中创建CNAME文件，然后将个人域名 <a href="https://lestatzhang.com/" target="_blank" rel="noopener">lestatzhang.com</a>添加进CNAME之后重新部署网站。<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd themes/next/source/</span><br><span class="line">echo "lestatzhang.com" &gt; CNAME</span><br><span class="line">cd ../../../'</span><br><span class="line">hexo d</span><br></pre></td></tr></table></figure></p><h3 id="TO-DO"><a href="#TO-DO" class="headerlink" title="TO-DO"></a>TO-DO</h3><p>具体博客搭建的步骤就这些了，后面主要是如何对网站页面/主题进行优化的过程。 TO-DO</p>]]></content>
      
      
      <categories>
          
          <category> Mac </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mac </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关于kafka中的反序列化</title>
      <link href="/2019/05/12/%E5%85%B3%E4%BA%8Ekafka%E4%B8%AD%E7%9A%84%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96/"/>
      <url>/2019/05/12/%E5%85%B3%E4%BA%8Ekafka%E4%B8%AD%E7%9A%84%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p><strong>Kafka生产者</strong>需要序列化程序将==对象转换为字节数组==，然后发送到Kafka。 同样，Kafka消费者需要使用<strong>反序列化器</strong>将从Kafka收到的==字节数组转换为Java对象==。 在前面的示例中，我们假设每个消息的键和值都是字符串，我们在消费者配置中使用了默认的StringDeserializer。</p><p>在第3章关于Kafka生产者的过程中，我们了解了如何自定义序列化类型以及如何使用Avro和AvroSerializer根据模式定义生成Avro对象，然后在向Kafka生成消息时对其进行序列化。 我们现在将介绍如何为自己的对象创建自定义反序列化器以及如何使用Avro及其反序列化器。</p><p>很明显，用于向Kafka生成事件的序列化程序必须与消耗事件时将使用的反序列化程序匹配。 假如我们使用IntSerializer进行序列化，然后使用StringDeserializer进行反序列化，这很有可能出现意想不到的结果。 这意味着作为开发人员，你需要跟踪用于写入每个主题的序列化程序，并确保每个主题仅包含你使用的反序列化程序可以解析的数据。 这是使用Avro和Schema Repository进行序列化和反序列化的好处之一 —— AvroSerializer可以确保写入特定主题的所有数据都与主题的模式兼容，这意味着它可以通过匹配的反序列化器和模式进行反序列化 。 生产者或消费者方面的兼容性错误将通过适当的错误消息轻松捕获，这意味着我们不需要尝试调试字节数组以查找序列化错误。</p><p>我们将首先快速展示如何编写自定义反序列化器，即使这是不太常用的方法，然后我们将继续讨论如何使用Avro反序列化消息键和值的示例。</p><h3 id="Custom-deserializers"><a href="#Custom-deserializers" class="headerlink" title="Custom deserializers"></a>Custom deserializers</h3><p>让我们采用第3章中序列化的相同自定义对象，并为其编写反序列化器：<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Customer</span> </span>&#123;</span><br><span class="line">            <span class="keyword">private</span> <span class="keyword">int</span> customerID;</span><br><span class="line">            <span class="keyword">private</span> String customerName;</span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="title">Customer</span><span class="params">(<span class="keyword">int</span> ID, String name)</span> </span>&#123;</span><br><span class="line">                    <span class="keyword">this</span>.customerID = ID;</span><br><span class="line">                    <span class="keyword">this</span>.customerName = name;</span><br><span class="line">&#125;</span><br><span class="line">      <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getID</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> customerID;</span><br><span class="line">&#125;</span><br><span class="line">      <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">       <span class="keyword">return</span> customerName;</span><br><span class="line">&#125; &#125;</span><br></pre></td></tr></table></figure></p><p>自定义反序列化器将如下所示：<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.kafka.common.errors.SerializationException;</span><br><span class="line">    <span class="keyword">import</span> java.nio.ByteBuffer;</span><br><span class="line">    <span class="keyword">import</span> java.util.Map;</span><br><span class="line">    <span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomerDeserializer</span> <span class="keyword">implements</span></span></span><br><span class="line"><span class="class">      <span class="title">Deserializer</span>&lt;<span class="title">Customer</span>&gt; </span>&#123; <span class="comment">//[1]</span></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">      <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Map configs, <span class="keyword">boolean</span> isKey)</span> </span>&#123;</span><br><span class="line">       <span class="comment">// nothing to configure</span></span><br><span class="line">      &#125;</span><br><span class="line">      <span class="meta">@Override</span></span><br><span class="line">      <span class="function"><span class="keyword">public</span> Customer <span class="title">deserialize</span><span class="params">(String topic, <span class="keyword">byte</span>[] data)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> id;</span><br><span class="line">        <span class="keyword">int</span> nameSize;</span><br><span class="line">        String name;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">          <span class="keyword">if</span> (data == <span class="keyword">null</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">          <span class="keyword">if</span> (data.length &lt; <span class="number">8</span>)</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> SerializationException(<span class="string">"Size of data received by</span></span><br><span class="line"><span class="string">              IntegerDeserializer is shorter than expected"</span>);</span><br><span class="line">          ByteBuffer buffer = ByteBuffer.wrap(data);</span><br><span class="line">          id = buffer.getInt();</span><br><span class="line">          String nameSize = buffer.getInt();</span><br><span class="line">          <span class="keyword">byte</span>[] nameBytes = <span class="keyword">new</span> Array[Byte](nameSize);</span><br><span class="line">          buffer.get(nameBytes);</span><br><span class="line">          name = <span class="keyword">new</span> String(nameBytes, <span class="string">'UTF-8'</span>);</span><br><span class="line">          <span class="keyword">return</span> <span class="keyword">new</span> Customer(id, name); <span class="comment">//[2]</span></span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">         <span class="keyword">throw</span> <span class="keyword">new</span> SerializationException(<span class="string">"Error when serializing Customer</span></span><br><span class="line"><span class="string">           to byte[] "</span> + e);</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line">      <span class="meta">@Override</span></span><br><span class="line">      <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;</span><br><span class="line">              <span class="comment">// nothing to close</span></span><br><span class="line">&#125; &#125;</span><br></pre></td></tr></table></figure></p><blockquote><p>[1]: 消费者还需要Customer类的实现，并且类和序列化器都需要匹配生产和消费应用程序。 在一个拥有许多消费者和生产者共享数据访问权限的大型组织中，这可能变得具有挑战性。[2]我们只是在这里颠倒串行器的逻辑 - 我们从字节数组中获取客户ID和名称，并使用它们构造我们需要的对象。</p></blockquote><p>使用此序列化程序的使用者代码与此示例类似：<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">    props.put(<span class="string">"bootstrap.servers"</span>, <span class="string">"broker1:9092,broker2:9092"</span>);</span><br><span class="line">    props.put(<span class="string">"group.id"</span>, <span class="string">"CountryCounter"</span>);</span><br><span class="line">    props.put(<span class="string">"key.deserializer"</span>,</span><br><span class="line">       <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line">    props.put(<span class="string">"value.deserializer"</span>,</span><br><span class="line">       <span class="string">"org.apache.kafka.common.serialization.CustomerDeserializer"</span>);</span><br><span class="line">    KafkaConsumer&lt;String, Customer&gt; consumer =</span><br><span class="line">      <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);</span><br><span class="line">    consumer.subscribe(<span class="string">"customerCountries"</span>)</span><br><span class="line">    <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">        ConsumerRecords&lt;String, Customer&gt; records =</span><br><span class="line">          consumer.poll(<span class="number">100</span>);</span><br><span class="line">        <span class="keyword">for</span> (ConsumerRecord&lt;String, Customer&gt; record : records)</span><br><span class="line">        &#123;</span><br><span class="line">        System.out.println(<span class="string">"current customer Id: "</span> +</span><br><span class="line">        record.value().getId() + <span class="string">" and</span></span><br><span class="line"><span class="string">           current customer name: "</span> + record.value().getName());</span><br><span class="line">&#125; &#125;</span><br></pre></td></tr></table></figure></p><p>同样，重要的是要注意不建议实现自定义序列化器和反序列化器。 它紧密地耦合了生产者和消费者，并且易碎且容易出错。 ==更好的解决方案是使用标准消息格式，如JSON，Thrift，Protobuf或Avro==。 我们现在将看到如何将Avro反序列化器与Kafka消费者一起使用。 </p><h3 id="使用Avro反序列化与Kafka消费者"><a href="#使用Avro反序列化与Kafka消费者" class="headerlink" title="使用Avro反序列化与Kafka消费者"></a>使用Avro反序列化与Kafka消费者</h3><p>假设我们正在使用第3章中显示的Avro中Customer类的实现。为了从Kafka中使用这些对象，你希望实现类似于此的消费应用程序：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">    props.put(<span class="string">"bootstrap.servers"</span>, <span class="string">"broker1:9092,broker2:9092"</span>);</span><br><span class="line">    props.put(<span class="string">"group.id"</span>, <span class="string">"CountryCounter"</span>);</span><br><span class="line">    props.put(<span class="string">"key.serializer"</span>,</span><br><span class="line">       <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line">    props.put(<span class="string">"value.serializer"</span>,</span><br><span class="line">       <span class="string">"io.confluent.kafka.serializers.KafkaAvroDeserializer"</span>); <span class="comment">//[1]</span></span><br><span class="line">    props.put(<span class="string">"schema.registry.url"</span>, schemaUrl); <span class="comment">//[2]</span></span><br><span class="line">    String topic = <span class="string">"customerContacts"</span></span><br><span class="line">    KafkaConsumer consumer = <span class="keyword">new</span></span><br><span class="line">       KafkaConsumer(createConsumerConfig(brokers, groupId, url));</span><br><span class="line">    consumer.subscribe(Collections.singletonList(topic));</span><br><span class="line">    System.out.println(<span class="string">"Reading topic:"</span> + topic);</span><br><span class="line">    <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">        ConsumerRecords&lt;String, Customer&gt; records =</span><br><span class="line">          consumer.poll(<span class="number">1000</span>); <span class="comment">//[3]</span></span><br><span class="line">        <span class="keyword">for</span> (ConsumerRecord&lt;String, Customer&gt; record: records) &#123;</span><br><span class="line">            System.out.println(<span class="string">"Current customer name is: "</span> +</span><br><span class="line">               record.value().getName()); <span class="comment">//[4]</span></span><br><span class="line">&#125;</span><br><span class="line">        consumer.commitSync();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><blockquote><p>[1] 我们使用KafkaAvroDeserializer来反序列化Avro消息。[2] schema.registry.url是一个新参数。 这只是指向我们存储模式的位置。 这样，消费者可以使用生产者注册的模式来反序列化消息。[3] 我们将生成的类Customer指定为记录值的类型。[4] record.value()是一个Customer实例，我们可以相应地使用它。</p></blockquote><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="https://www.oreilly.com/library/view/kafka-the-definitive/9781491936153/ch04.html" target="_blank" rel="noopener">Chapter 4. Kafka Consumers: Reading Data from Kafka#Deserializers</a></p>]]></content>
      
      
      <categories>
          
          <category> Kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
            <tag> Deserializer </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关于Spark Dataset API中的Typed transformations和Untyped transformations</title>
      <link href="/2019/03/17/%E5%85%B3%E4%BA%8ESpark%20Dataset%20API%E4%B8%AD%E7%9A%84Typed%20transformations%E5%92%8CUntyped%20transformations/"/>
      <url>/2019/03/17/%E5%85%B3%E4%BA%8ESpark%20Dataset%20API%E4%B8%AD%E7%9A%84Typed%20transformations%E5%92%8CUntyped%20transformations/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>学习Spark源代码的过程中遇到了Typed transformations和Untyped transformations两个概念，整理了以下相关的笔记。对于这两个概念，不知道怎么翻译好，个人理解为强类型转换和弱类型转换，也不知道对不对，欢迎各位大神指正。</p><h2 id="关于Dataset"><a href="#关于Dataset" class="headerlink" title="关于Dataset"></a>关于Dataset</h2><p>Dataset是特定领域对象(domain-specific object)的强类型集合，它可以使用函数或关系运算进行并行转换。 每个Dataset还有一个名为DataFrame的弱类型视图，相当于<code>Dataset[Row]</code>。对于Spark(Scala)，DataFrames只是类型为Row的Dataset。 “Row”类型是Spark中用于计算的，优化过的，in-memory的一种内部表达。</p><p>Dataset上可用的操作分为 <strong>转换(transformation)</strong> 和 <strong>执行(action)</strong> 两种。</p><ul><li>Transformation操作可以产生新的Dataset，如map，filter，select和aggregate（groupBy）等。</li><li>Action操作触发计算和返回结果。 如count，show或写入文件系统等。</li></ul><h2 id="关于Dataset-API"><a href="#关于Dataset-API" class="headerlink" title="关于Dataset API"></a>关于Dataset API</h2><h3 id="Typed-and-Un-typed-APIs"><a href="#Typed-and-Un-typed-APIs" class="headerlink" title="Typed and Un-typed APIs"></a>Typed and Un-typed APIs</h3><p>实质上，在Saprk的结构化API中，可以分成两类，“无类型(untyped)”的DataFrame API和“类型化(typed)”的Dataset API。 确切的说Dataframe并不是”无类型”的, 它们有类型，只是类型检查没有那么严格，只检查这些类型是否在 ==运行时(run-time)== 与schema中指定的类型对齐。 而Dataset在 ==编译时(compile-time)== 就会检查类型是否符合规范。 </p><p>Dataset API仅适用于 ==基于JVM的语言(Scala和Java)==。我们可以使用Scala 中的case class或Java bean来进行类型指定。</p><p>关于不同语言中的可用API可参考下表。</p><table><thead><tr><th>Language</th><th>Main Abstraction</th></tr></thead><tbody><tr><td>Scala</td><td>Dataset[T] &amp; DataFrame (alias for Dataset[Row])</td></tr><tr><td>Java</td><td>Dataset[T]</td></tr><tr><td>Python<em></em></td><td>DataFrame</td></tr><tr><td>R</td><td>DataFrame</td></tr></tbody></table><blockquote><p>由于Python和R没有<code>compile-time type-safety</code>，因此只有 Untyped API，即DataFrames。</p></blockquote><h2 id="关于Transformations"><a href="#关于Transformations" class="headerlink" title="关于Transformations"></a>关于Transformations</h2><p>转换(transformation)可以被分为:</p><ul><li><strong>强类型转换(Typed transformations)</strong></li><li><strong>弱类型转换(Untyped transformations)</strong><h3 id="Typed-transformations-vs-Untyped-transformations"><a href="#Typed-transformations-vs-Untyped-transformations" class="headerlink" title="Typed transformations vs Untyped transformations"></a>Typed transformations vs Untyped transformations</h3>简单来说，如果转换是弱类型的，它将返回一个Dataframe(==确切的说弱类型转换的返回类型还有 <strong><em>Column</em></strong>,  <strong><em>RelationalGroupedDataset</em></strong>, <strong><em>DataFrameNaFunctions</em></strong>  和 <strong><em>DataFrameStatFunctions</em></strong>  等==)，而强类型转换返回的是一个Dataset。 在源代码中，我们可以看到弱类型转换API的返回类型是Dataframe而不是Dataset，且带有<code>@group untypedrel</code>的注释。 因此，我们可以通过检查该方法的签名来确定它是否是弱类型的(untyped)。<blockquote><p>强类型转换API带有<code>@group typedrel</code>的注释</p></blockquote></li></ul><p>例如Dataset.scala类中的<a href="https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/Dataset.scala#L864-L876" target="_blank" rel="noopener">join方法</a>就属于弱类型转换(untyped transformations).<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Join with another `DataFrame`.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Behaves as an INNER JOIN and requires a subsequent join predicate.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> right Right side of the join operation.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@group</span> untypedrel</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@since</span> 2.0.0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function">def <span class="title">join</span><span class="params">(right: Dataset[_])</span>: DataFrame </span>= withPlan &#123;</span><br><span class="line">  Join(logicalPlan, right.logicalPlan, joinType = Inner, None, JoinHint.NONE)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>通常，任何更改Dataset列类型或添加新列的的转换是弱类型。 当我们需要修改Dataset的schema时，我们就需要退回到Dataframe进行操作。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://www.oreilly.com/library/view/spark-the-definitive/9781491912201/ch04.html" target="_blank" rel="noopener">Structured API Overview</a><a href="http://apache-spark-user-list.1001560.n3.nabble.com/Difference-between-Typed-and-untyped-transformation-in-dataset-API-td34650.html" target="_blank" rel="noopener">Difference-between-Typed-and-untyped-transformation-in-dataset-API</a><a href="https://databricks.com/blog/2016/07/14/a-tale-of-three-apache-spark-apis-rdds-dataframes-and-datasets.html" target="_blank" rel="noopener">RDDs vs DataFrames and Datasets</a><a href="https://jaceklaskowski.gitbooks.io/mastering-spark-sql/spark-sql-dataset-operators.html" target="_blank" rel="noopener">spark-sql-dataset-operators</a><a href="https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset" target="_blank" rel="noopener">org.apache.spark.sql.Dataset</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> Spark </tag>
            
            <tag> dataset </tag>
            
            <tag> transformations api </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关于Kafka Replication机制</title>
      <link href="/2019/03/11/%E5%85%B3%E4%BA%8EKafka%20Replication%E6%9C%BA%E5%88%B6/"/>
      <url>/2019/03/11/%E5%85%B3%E4%BA%8EKafka%20Replication%E6%9C%BA%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<h3 id="Replication"><a href="#Replication" class="headerlink" title="Replication"></a>Replication</h3><ul><li>Kafka的replication复制机制是其可靠性的保证，即为每个分区数据提供多个副本。</li><li>每个Kafka topic包含有多个分区，分区是kafka存储数据的基本单位。==一个分区只能存储在同一个硬盘上==。</li><li>Kafka保证每一个分区内的消息的顺序，无论这个分区是在线(available)的还是离线的(unavailable)。</li><li>每个分区拥有多个副本，其中一个副本将被指定为主副本(leader replicas)，其余的为跟随副本(follower)</li><li>==所有的消息都会写入到主副本，所有的消息都从主要副本读取==，其他的副本只需要保持于主副本同步即可</li><li>当主副本离线时，其他的副本中的一个将会被推选为新的主副本（一般为该分区副本列表的下一个副本）</li><li><p>关于副本是否处于“同步中(in-sync)”的状态的判断标准：</p><ul><li>如果它是主副本，那么它是处于“同步中(in-sync)”的状态。</li><li><p>如果它是跟随副本， 且拥有以下状态，那么它处于“同步中(in-sync)”：</p><ul><li>它与zookeeper有一个可用的session（在最近6秒内给zk发送过心跳）</li><li>它在最近10秒内从主副本获取过消息</li><li>它在最近10秒从主副本获取过最新的消息</li></ul><p>否则，该副本的状态为“不同步(out-of-sync)”</p></li></ul></li><li>当一个同步中的副本出现延迟时，它会影响生产者和消费者的性能。因为只有在所有跟随副本同步完所有消息并且提交后，它们才会继续执行。</li></ul>]]></content>
      
      
      <categories>
          
          <category> Kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>一些程序员必备的英语词汇及释义</title>
      <link href="/2019/03/02/%E4%B8%80%E4%BA%9B%E7%A8%8B%E5%BA%8F%E5%91%98%E5%BF%85%E5%A4%87%E7%9A%84%E8%8B%B1%E8%AF%AD%E8%AF%8D%E6%B1%87%E5%8F%8A%E9%87%8A%E4%B9%89/"/>
      <url>/2019/03/02/%E4%B8%80%E4%BA%9B%E7%A8%8B%E5%BA%8F%E5%91%98%E5%BF%85%E5%A4%87%E7%9A%84%E8%8B%B1%E8%AF%AD%E8%AF%8D%E6%B1%87%E5%8F%8A%E9%87%8A%E4%B9%89/</url>
      
        <content type="html"><![CDATA[<h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p>看书整理的时候遇到一些词汇不知道怎么翻译成中文好，于是整理了一些词汇解释的笔记，整理成如下词汇表</p><h4 id="词汇表"><a href="#词汇表" class="headerlink" title="词汇表"></a>词汇表</h4><div class="table-box"><table cellspacing="0"><tbody><tr><td style="vertical-align:bottom;width:120pt;"><span style="color:#000000;">angle brackets</span></td>            <td style="vertical-align:bottom;width:80pt;"><span style="color:#000000;">尖括号</span></td>            <td style="vertical-align:bottom;width:65pt;"><span style="color:#000000;">iterate over</span></td>            <td style="vertical-align:bottom;width:65pt;"><span style="color:#000000;">迭代</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">array buffers&nbsp;</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">数组缓冲</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">iterator</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">迭代器</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">asynchronous</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">异步的</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">jump tables</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">跳转表</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">atom</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">原子</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">lexers</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">词法分析器</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">auxiliary constructors</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">辅助构造器</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">lexical analysis</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">词法分析</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">backslashes</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">反斜杠</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">linked list</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">链表</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">backtracking</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">回溯</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">listeners</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">监听器</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">base class</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">基类</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">markup&nbsp;</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">标记</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">blocking</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">阻塞的</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">multiple inheritance</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">多重继承</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">call-by-name</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">传名调用</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">mutators</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">改值器</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">call-by-value</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">传值调用</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">namespace</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">命名空间</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">case classes</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">样例类</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">nested</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">嵌套的</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">case objects</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">样例对象</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">notation</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">表示法</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">checked exception</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">受检异常</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">overflow</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">溢出</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">closure</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">闭包</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">override</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">重写/覆盖</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">companion classes</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">伴生类</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">parser trees</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">解析树</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">companion objects</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">伴生对象</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">partial functions</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">偏函数</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">compile-time</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">编译期的</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">partially applied functions</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">部分应用函数</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">comprehensions</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">推导式</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">pass-by-name</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">传名的</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">concurrency</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">并发</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">pattern matching</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">模式匹配</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">consistency</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">一致性</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">polymorphism</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">多态</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">contravariant</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">逆变的</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">primary constructors</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">主构造器</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">control flow</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">控制流转</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">procedures</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">过程</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">covariant</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">协变的</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">processes</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">进程</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">currying</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">柯里化</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">projection</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">投影</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">deadlocks</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">死锁</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">properties</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">属性</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">delimited continuation</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">定界延续</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">ragged</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">不规则的</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">dependency injection</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">依赖注入</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">random access</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">随机访问</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">deprecated</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">已过时的</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">recursive</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">递归的</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">destructors</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">析构器</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">reference types</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">引用类型</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">discard</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">丢弃</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">reflective calls</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">反射调用</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">domain-specific languages</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">领域特定语言</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">regex</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">正则</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">duck typing</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">鸭子类型</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">regular expression</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">正则表达式</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">dynamically typed languages</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">动态类型语言</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">runtime</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">运行时的</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">elitable</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">可省略的</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">sealed class</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">密封类</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">embedded</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">内嵌的</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">selectors</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">选取器</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">enumerations</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">枚举</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">self types</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">自身类型</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">evaluate</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">求值</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">self-closing tags</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">自结束的标签</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">exhaustive</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">穷举的</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">serialization</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">序列化</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">explicit</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">显式的</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">singleton</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">单例</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">extractors</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">提取器</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">square brackets</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">方括号</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">family polymorphism</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">家族多态</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">stack</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">栈</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">for comprehension</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">for 推导式</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">structural types</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">结构类型</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">form</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">范式</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">subclass</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">子类</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">generators</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">生成器</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">superclasses</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">超类</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">generics</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">泛型</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">supertypes</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">超类型</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">hash maps</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">哈希映射</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">synchronous</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">同步的</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">hash tables</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">哈希表</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">syntactic sugar</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">语法糖</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">heterogenerous</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">异构的</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">tab completion</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">Tab键补全</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">higher-kinded types</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">高等类型</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">tail recursive</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">尾递归</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">higher-order functions</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">高阶函数</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">threads</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">线程</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">immutable</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">不可变的</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">transient</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">瞬态的</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">implement</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">实现</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">tuples</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">元祖</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">implicit</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">隐式的</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">typesafe</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">类型安全的</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">implicit conversion</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">隐式转换</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">unary</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">一元的</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">implicit parameters</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">隐式参数</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">unevaluated</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">为求值得</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">inference</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">推断</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">volatile</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">易失的</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">instance</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">实例</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">wildcards</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">通配符</span></td>        </tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">invoke</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">执行/调用</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">warppers</span></td>            <td style="vertical-align:bottom;"><span style="color:#000000;">包装</span></td>        </tr></tbody></table></div>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>ETL工具Talend最佳实践</title>
      <link href="/2019/03/01/ETL%E5%B7%A5%E5%85%B7Talend%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/"/>
      <url>/2019/03/01/ETL%E5%B7%A5%E5%85%B7Talend%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</url>
      
        <content type="html"><![CDATA[<h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p>和Talend这款软件打交道有一段时间了，主要用它来做一些ETL相关的作业开发，以下总结了一些自己配置与开发过程中的最佳实践。</p><h4 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h4><ol><li><p>可以通过修改Talend Studio 的 <strong>.ini</strong> 配置文件来给其分配更多的内存，例如，以下是我在64位8GB内存的电脑配置的参数</p><table><tr><td align="left">-vmargs <br>-Xms2014m <br>-Xmx4096m <br>-XX:MaxPermSize=512m <br>-Dfile.encoding=UTF-8 <br></td></tr></table></li><li><p>在开发过程中一定要注意对Null值得处理</p></li><li>可以创建Repository Metadata用于数据库连接</li><li>可以使用 ==t\<db>== 的数据连接组件定义数据库连接，并重复使用。</db></li><li>记得使用 ==t\<db>== 组件来关闭数据库连接</db></li><li>避免在Talend的组件中在使用硬编码值(hard coding)，使用Talend context 变量代替</li><li>尽可能使用变量代替硬编码</li><li>对于频繁的变换，可以通过创建routines或者functions来减少工作量</li><li>每次关机前记得保存并关闭Talend Studio！！！</li><li>尽可能早的使用tFilterColumns组件过滤去不需要的字段/列</li><li>尽可能早的使用tFilterRows组件过滤去不需要的数据</li><li>使用Select列表达式从数据库获取数据，尽量避免获取不需要的字段</li><li>当作业出现OOM错误时，调整JVM的参数，例如修改Xms和Xmx来分配更多的内存</li><li>通过使用并行化选项来提高作业性能，减少整体的运行时间，如并行化从数据读写数据等</li><li>给Main job起一个有意义的名字</li><li>在定义Sub job时，务必第一时间记录子作业的标题、描述和目的。</li><li>在设计作业尽可能将复杂的作业切割成一个个小作业</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> ETL </tag>
            
            <tag> Talend </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark中RDD、DataFrame和DataSet的区别</title>
      <link href="/2019/03/01/Spark%E4%B8%ADRDD%E3%80%81DataFrame%E5%92%8CDataSet%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
      <url>/2019/03/01/Spark%E4%B8%ADRDD%E3%80%81DataFrame%E5%92%8CDataSet%E7%9A%84%E5%8C%BA%E5%88%AB/</url>
      
        <content type="html"><![CDATA[<h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p>最近同事开始学习使用Spark，问我RDD、DataFrame和DataSet之间有什么区别，以及生产环境中的spark1.6将在不久后被移除，全部使用spark2+。于是今天我就借机整理了以下它们三者之间的异同。</p><h4 id="RDD、DataFrame和DataSet的定义"><a href="#RDD、DataFrame和DataSet的定义" class="headerlink" title="RDD、DataFrame和DataSet的定义"></a>RDD、DataFrame和DataSet的定义</h4><p>在开始Spark RDD与DataFrame与Dataset之间的比较之前，先让我们看一下Spark中的RDD，DataFrame和Datasets的定义：</p><ul><li><strong>Spark RDD</strong> RDD代表弹性分布式数据集。它是记录的只读分区集合。 RDD是Spark的基本数据结构。它允许程序员以容错方式在大型集群上执行内存计算。</li><li><strong>Spark Dataframe</strong> 与RDD不同，数据组以列的形式组织起来，类似于关系数据库中的表。它是一个不可变的分布式数据集合。 Spark中的DataFrame允许开发人员将数据结构(类型)加到分布式数据集合上，从而实现更高级别的抽象。<ul><li><strong>Spark Dataset</strong> Apache Spark中的Dataset是DataFrame API的扩展，它提供了类型安全(type-safe)，面向对象(object-oriented)的编程接口。 Dataset利用Catalyst optimizer可以让用户通过类似于sql的表达式对数据进行查询。</li></ul></li></ul><h4 id="RDD、DataFrame和DataSet的比较"><a href="#RDD、DataFrame和DataSet的比较" class="headerlink" title="RDD、DataFrame和DataSet的比较"></a>RDD、DataFrame和DataSet的比较</h4><h5 id="Spark版本"><a href="#Spark版本" class="headerlink" title="Spark版本"></a>Spark版本</h5><ul><li>RDD – 自Spark 1.0起</li><li>DataFrames – 自Spark 1.3起</li><li>DataSet – 自Spark 1.6起</li></ul><h5 id="数据表示形式"><a href="#数据表示形式" class="headerlink" title="数据表示形式"></a>数据表示形式</h5><ul><li>RDD RDD是分布在集群中许多机器上的数据元素的分布式集合。 RDD是一组表示数据的Java或Scala对象。</li><li>DataFrameDataFrame是命名列构成的分布式数据集合。 它在概念上类似于关系数据库中的表。</li><li>Dataset它是DataFrame API的扩展，提供RDD API的类型安全，面向对象的编程接口以及Catalyst查询优化器的性能优势和DataFrame API的堆外存储机制的功能。</li></ul><h5 id="数据格式"><a href="#数据格式" class="headerlink" title="数据格式"></a>数据格式</h5><ul><li>RDD 它可以轻松有效地处理结构化和非结构化的数据。 和Dataframe和DataSet一样，RDD不会推断出所获取的数据的结构类型，需要用户来指定它。</li><li>DataFrame 仅适用于结构化和半结构化数据。 它的数据以命名列的形式组织起来。 </li><li>DataSet 它也可以有效地处理结构化和非结构化数据。 它表示行(row)的JVM对象或行对象集合形式的数据。 它通过编码器以表格形式(tabular forms)表示。</li></ul><h5 id="编译时类型安全"><a href="#编译时类型安全" class="headerlink" title="编译时类型安全"></a>编译时类型安全</h5><ul><li>RDDRDD提供了一种熟悉的面向对象编程风格，具有编译时类型安全性。</li><li>DataFrame如果您尝试访问表中不存在的列，则持编译错误。 它仅在运行时检测属性错误。</li><li>DataSet DataSet可以在编译时检查类型, 它提供编译时类型安全性。[TO-DO 什么是编译时的类型安全]<h5 id="序列化"><a href="#序列化" class="headerlink" title="序列化"></a>序列化</h5></li><li>RDD每当Spark需要在集群内分发数据或将数据写入磁盘时，它就会使用Java序列化。序列化单个Java和Scala对象的开销很昂贵，并且需要在节点之间发送数据和结构。</li><li><p>DataFrameSpark DataFrame可以将数据序列化为二进制格式的堆外存储（在内存中），然后直接在此堆内存上执行许多转换。无需使用java序列化来编码数据。它提供了一个Tungsten物理执行后端，来管理内存并动态生成字节码以进行表达式评估。</p></li><li><p>DataSet 在序列化数据时，Spark中的数据集API具有编码器的概念，该编码器处理JVM对象与表格表示之间的转换。它使用spark内部Tungsten二进制格式存储表格表示。数据集允许对序列化数据执行操作并改善内存使用。它允许按需访问单个属性，而不会消灭整个对象。</p></li></ul><h5 id="垃圾回收"><a href="#垃圾回收" class="headerlink" title="垃圾回收"></a>垃圾回收</h5><ul><li>RDD创建和销毁单个对象会导致垃圾回收。<ul><li>DataFrame避免在为数据集中的每一行构造单个对象时引起的垃圾回收。</li></ul></li><li>DataSet因为序列化是通过Tungsten进行的，它使用了off heap数据序列化，不需要垃圾回收器来摧毁对象</li></ul><h5 id="效率-内存使用"><a href="#效率-内存使用" class="headerlink" title="效率/内存使用"></a>效率/内存使用</h5><ul><li>RDD在java和scala对象上单独执行序列化时，效率会降低，这需要花费大量时间。</li><li>DataFrame使用off heap内存进行序列化可以减少开销。 它动态生成字节代码，以便可以对该序列化数据执行许多操作。 无需对小型操作进行反序列化。</li><li>DataSet它允许对序列化数据执行操作并改善内存使用。 因此，它可以允许按需访问单个属性，而无需反序列化整个对象。</li></ul><h5 id="编程语言支持"><a href="#编程语言支持" class="headerlink" title="编程语言支持"></a>编程语言支持</h5><ul><li>RDDRDD提供Java，Scala，Python和R语言的API。 因此，此功能为开发人员提供了灵活性。</li><li>DataFrameDataFrame同样也提供Java，Scala，Python和R语言的API</li><li>DataSet Dataset 的一些API目前仅支持Scala和Java，对Python和R语言的API在陆续开发中</li></ul><h5 id="聚合操作-Aggregation"><a href="#聚合操作-Aggregation" class="headerlink" title="聚合操作(Aggregation)"></a>聚合操作(Aggregation)</h5><ul><li>RDDRDD API执行简单的分组和聚合操作的速度较慢。</li><li>DataFrameDataFrame API非常易于使用。 探索性分析更快，在大型数据集上创建汇总统计数据。</li><li>DataSet在Dataset中，对大量数据集执行聚合操作的速度更快。</li></ul><h4 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h4><ul><li>当我们需要对数据集进行底层的转换和操作时， 可以选择使用RDD</li><li>当我们需要高级抽象时，可以使用DataFrame和Dataset API。</li><li>对于非结构化数据，例如媒体流或文本流，同样可以使用DataFrame和Dataset API。</li><li>我们可以使用DataFrame和Dataset 中的高级的方法。 例如，filter, maps, aggregation, sum, SQL queries以及通过列访问数据等如果您不关心在按名称或列处理或访问数据属性时强加架构（例如列式格式）。另外，如果我们想要在编译时更高程度的类型安全性。</li></ul><p>RDD提供更底层功能， DataFrame和Dataset则允许创建一些自定义的结构，拥有高级的特定操作，节省空间并高速执行。 </p><p>为了确保我们的代码能够尽可能的利用Tungsten优化带来的好处，推荐使用Scala的 Dataset API（而不是RDD API）。</p><p>Dataset即拥有DataFrame带来的relational transformation的便捷，也拥有RDD中的functional transformation的优势。 </p><p>参考资料<a href="https://data-flair.training/blogs/apache-spark-rdd-vs-dataframe-vs-dataset/" target="_blank" rel="noopener">apache-spark-rdd-vs-dataframe-vs-dataset</a></p>]]></content>
      
      
      <categories>
          
          <category> Spark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>一些常用的Spark SQL调优技巧</title>
      <link href="/2019/03/01/%E4%B8%80%E4%BA%9B%E5%B8%B8%E7%94%A8%E7%9A%84Spark%20SQL%E8%B0%83%E4%BC%98%E6%8A%80%E5%B7%A7/"/>
      <url>/2019/03/01/%E4%B8%80%E4%BA%9B%E5%B8%B8%E7%94%A8%E7%9A%84Spark%20SQL%E8%B0%83%E4%BC%98%E6%8A%80%E5%B7%A7/</url>
      
        <content type="html"><![CDATA[<h5 id="一些常用的Spark-SQL调优技巧"><a href="#一些常用的Spark-SQL调优技巧" class="headerlink" title="一些常用的Spark SQL调优技巧"></a>一些常用的Spark SQL调优技巧</h5><ol><li><p>使用缓存表在sparksql中，当我们创建表时，我们可以通过调用<code>spark.catalog.cacheTable(&quot;tableName&quot;)</code> 或者 <code>dataFrame.cache()</code>的方式将表缓存起来。这样Spark SQL将仅扫描所需的列，并自动调整压缩以最小化内存使用和GC压力。当你不需要缓存时，可以通过使用<code>spark.catalog.uncacheTable(&quot;tableName&quot;)</code>将其移除缓存。</p><p> 此外，我们还可以通过设置<code>spark.sql.inMemoryColumnarStorage.batchSize</code>来调整列缓存batch的大，例如在提交spark作业时候，指定以下参数：</p><pre><code>--conf &quot;spark.sql.inMemoryColumnarStorage.batchSize=10000&quot;</code></pre><p> 较大的batch size可以提高内存利用率和压缩率，但在缓存数据时<font color="red"><b>存在OOM风险。</b></font></p></li><li><p>调整Shuffle分区我可以通过调整在对数据进行shuffle或者aggregation操作时的分区数目来提高性能。分区数和reduce任务数是相同的。如果reducer具有资源密集型操作，那么增加shuffle分区将增加并行性，同时还可以更好地利用资源并最小化每个任务的负载。我们可以通过设置<code>spark.sql.shuffle.partitions</code>来调整spark sql作业中的shuffle分区数(默认值为200).例如在提交spark作业时候，指定以下参数：</p><pre><code>--conf &quot;spark.sql.shuffle.partitions=2000&quot;</code></pre></li><li><p>使用Broadcast JoinBroadcast Join接类似于Hive中的Map Join，其中较小的表将被加载到分布式缓存中，并且连接操作可以作为Map Only操作来完成。 默认情况下，Spark SQL中会启用广播连接。当然，我们也可以指定以下参数将其关闭：</p><pre><code>--conf“spark.sql.autoBroadcastJoinThreshold = -1”</code></pre><p> 这个参数是表示Broadcast Join时广播表大小的阈值，<code>-1</code>即可以理解为关闭Broadcast Join。当然当我们开启Broadcast Join时，也可以修改其数值来增加在执行连接操作时可以广播的表大小的最大值。 默认值为10 MB，例如我们可以通过以下设置将其大小更改为50MB：</p><pre><code>--conf &quot;spark.sql.autoBroadcastJoinThreshold = 50485760&quot;</code></pre></li></ol><p>参考资料：<a href="https://mapr.com/support/s/article/Spark-Troubleshooting-guide-Spark-SQL-Examples-of-commonly-used-Spark-SQLTuning-properties?language=en_US" target="_blank" rel="noopener">Spark-Troubleshooting-guide-Spark-SQL-Examples-of-commonly-used-Spark-SQLTuning-properties</a></p>]]></content>
      
      
      <categories>
          
          <category> Spark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
            <tag> sql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>spark.sql.shuffle.partitions 和 spark.default.parallelism 的区别</title>
      <link href="/2019/02/27/spark.sql.shuffle.partitions%20%E5%92%8C%20spark.default.parallelism%20%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
      <url>/2019/02/27/spark.sql.shuffle.partitions%20%E5%92%8C%20spark.default.parallelism%20%E7%9A%84%E5%8C%BA%E5%88%AB/</url>
      
        <content type="html"><![CDATA[<p>在关于spark任务并行度的设置中，有两个参数我们会经常遇到，spark.sql.shuffle.partitions 和 spark.default.parallelism, 那么这两个参数到底有什么区别的？</p><p>首先，让我们来看下它们的定义</p><table><thead><tr><th>Property Name</th><th>Default</th><th>Meaning</th></tr></thead><tbody><tr><td>spark.sql.shuffle.partitions</td><td>200</td><td align="left" width="200">Configures the number of partitions to use when shuffling data for <b>joins</b> or <b>aggregations</b>.</td></tr><tr><td>spark.default.parallelism</td><td align="left">For distributed shuffle operations like <strong>reduceByKey</strong> and <strong>join</strong>, the largest number of partitions in a parent RDD. <br><br>For operations like parallelize with no parent RDDs, it depends on the cluster manager: <br> <b>- Local mode:</b> number of cores on the local machine <br> <b>- Mesos fine grained mode</b>: 8 <br><b>- Others:</b> total number of cores on all executor nodes or 2, whichever is larger</td><td align="left">Default number of partitions in RDDs returned by transformations like <b>join</b>, <b>reduceByKey</b>, and parallelize when not set by user.</td></tr></tbody></table><p>看起来它们的定义似乎也很相似，但在实际测试中，</p><ul><li>spark.default.parallelism只有在处理RDD时才会起作用，对Spark SQL的无效。</li><li>spark.sql.shuffle.partitions则是对sparks SQL专用的设置</li></ul><p>我们可以在提交作业的通过 <code>--conf</code> 来修改这两个设置的值，方法如下：<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark-submit --conf spark.sql.shuffle.partitions=20 --conf spark.default.parallelism=20</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> Spark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
            <tag> Parallelism </tag>
            
            <tag> Tuning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>为什么建议在Spark中使用Scala定义UDF</title>
      <link href="/2019/02/18/why-use-scala-udf/"/>
      <url>/2019/02/18/why-use-scala-udf/</url>
      
        <content type="html"><![CDATA[<p>虽然在Pyspark中，驱动程序是一个python进程，但是它创建的SparkSession对象以及其他DataFrames或者RDDs等都是利用Python封装过的 ==JVM对象== 。简单地说，虽然控制程序是Python，但它实际上是python代码告诉集群上的分布式Scala程序该做什么。 数据存储在JVM的内存中，并由Scala代码进行转换。</p><p>将这些对象从JVM内存中取出并将它们转换为Python可以读取的形式（称为序列化和反序列化）的过程开销是很大的。 一般情况下，将计算结果收集回Python驱动程序通常针对低容量样本，并且不经常进行，因此这种开销相对不被注意。 但是，如果程序在集群中的对整个数据集的Python和JVM对象之间来回转换时，性能将会受到显著影响。</p><p><img src="./sparkudf.png" alt="Credit:  https://medium.com/wbaa/using-scala-udfs-in-pyspark-b70033dd69b9"></p><p>在上图中，Python程序的指令（1）被转换为Spark执行计划，并通过SparkSession JVM对象（2）传递给集群中不同机器上的两个执行程序（3）。 执行程序通常会从外部源（如HDFS）加载数据，在内存中执行某些转换，然后将数据写回外部存储。 数据将在程序的生命周期内保留在JVM（3）中。</p><p>而使用Python UDF时，数据必须经过几个额外的步骤。 首先，数据必须从Java（4）序列化，这样运行UDF所在的Python进程才可以将其读入（5）。 然后，Python运算完的结果经过一些列序列化和反序列化然后返回到JVM。</p><p>那么我们该如何优化呢？我们可以直接使用Scala来编写Spark UDF。Scala UDF可以直接在执行程序的JVM中运行，因此数据将跳过两轮序列化和反序列化，处理的效率将会比使用Python UDF高的多。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>启动Python进程的开销不小，但是真正的开销在于将数据序列化到Python中。推荐在Spark中定义UDF时首选Scala或Java，即使UDFs是用Scala/Java编写的，不用担心，我们依然可以在python(pyspark)中使用它们，简单实例如下：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### pyspark --jars [path/to/jar/x.jar]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Pre Spark 2.1,</span></span><br><span class="line">spark._jvm.com.test.spark.udf.MyUpper.registerUDF(spark._jsparkSession)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Spark 2.1+</span></span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StringType</span><br><span class="line">sqlContext.registerJavaFunction(<span class="string">"my_upper"</span>, <span class="string">"com.test.spark.udf.MyUpper"</span>, StringType())</span><br><span class="line"></span><br><span class="line"><span class="comment"># Spark 2.3+</span></span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StringType</span><br><span class="line">spark.udf.registerJavaFunction(<span class="string">"my_upper"</span>, <span class="string">"com.test.spark.udf.MyUpper"</span>, StringType())</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use your UDF</span></span><br><span class="line">spark.sql(<span class="string">"""SELECT my_upper('abeD123okoj')"""</span>).show()</span><br></pre></td></tr></table></figure></p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://medium.com/wbaa/using-scala-udfs-in-pyspark-b70033dd69b9" target="_blank" rel="noopener">Using Scala UDFs in PySpark</a></p><p><a href="http://shop.oreilly.com/product/0636920034957.do" target="_blank" rel="noopener">[BOOK] Spark - The Definitive Guide</a></p>]]></content>
      
      
      <categories>
          
          <category> Spark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
            <tag> Scala </tag>
            
            <tag> UDF </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mac上解决访问github慢之懒人版</title>
      <link href="/2019/02/18/Mac%E4%B8%8A%E8%A7%A3%E5%86%B3%E8%AE%BF%E9%97%AEgithub%E6%85%A2%E4%B9%8B%E6%87%92%E4%BA%BA%E7%89%88/"/>
      <url>/2019/02/18/Mac%E4%B8%8A%E8%A7%A3%E5%86%B3%E8%AE%BF%E9%97%AEgithub%E6%85%A2%E4%B9%8B%E6%87%92%E4%BA%BA%E7%89%88/</url>
      
        <content type="html"><![CDATA[<p>写了一个简单脚本用来解决Mac上访问github慢的问题，基本思路如下：</p><ol><li>访问 <a href="http://github.global.ssl.fastly.net.ipaddress.com/#ipinfo" target="_blank" rel="noopener">http://github.global.ssl.fastly.net.ipaddress.com/#ipinfo</a> 获取github的IP地址</li><li>在/etc/hosts中加入查询到的IP和域名 （需要root 权限）</li><li>在终端在输以下指令刷新DNS（需要root 权限）</li></ol><p>运行以下shell脚本即可，需要root权限。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>get the fastest github ip</span><br><span class="line">fast_ip=`curl http://github.global.ssl.fastly.net.ipaddress.com/#ipinfo 2&gt;/dev/null| grep -E -o "([0-9]&#123;1,3&#125;[\.])&#123;3&#125;[0-9]&#123;1,3&#125;" |sed -n '2p'`;</span><br><span class="line">echo $fast_ip;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>Add or replace the $fast_ip in /etc/hosts</span><br><span class="line">if grep "www.github.com" /etc/hosts &gt;/dev/null;then</span><br><span class="line">echo "github dns exists, replace it with the latest one $fast_ip";</span><br><span class="line">sed -i -e "s|[0-9]\&#123;1,3\&#125;\.[0-9]\&#123;1,3\&#125;\.[0-9]\&#123;1,3\&#125;\.[0-9]\&#123;1,3\&#125;  *www\.github\.com|$fast_ip www\.github\.com|"  /etc/hosts;</span><br><span class="line">else</span><br><span class="line">echo "github dns does not exist, replace it with the latest one $fast_ip";</span><br><span class="line">echo -e "\n#Github\n$fast_ip www.github.com\n" &gt;&gt; /etc/hosts;</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">killall -HUP mDNSResponder;say DNS cache has been flushed;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Mac </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mac </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mac共享主机网络给虚拟机</title>
      <link href="/2019/02/17/Mac%E5%85%B1%E4%BA%AB%E4%B8%BB%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%BB%99%E8%99%9A%E6%8B%9F%E6%9C%BA/"/>
      <url>/2019/02/17/Mac%E5%85%B1%E4%BA%AB%E4%B8%BB%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%BB%99%E8%99%9A%E6%8B%9F%E6%9C%BA/</url>
      
        <content type="html"><![CDATA[<p>因工作需要需要且身边没有windows系统的笔记本，无奈只好在mac上利用虚拟机安装一个win7系统作为临时过渡。我使用的虚拟机软件是Parallels Desktop（以下简称PD）<img src="./2019021611181380.png" width="30%" alt>PD提供三种不同网络模式供用户选择:</p><ul><li>共享网络（推荐）</li><li>桥接网络</li><li>Host-Only网络<img src="./20190216110149123.png" width="60%" alt></li></ul><p>各种网络模式的区别请移步<a href="https://kb.parallels.com/en/4948" target="_blank" rel="noopener">官方文档</a></p><p>一开始我并没有任何设置，直接使用默认的<strong>共享网络</strong>模式，使用过程中出现了有时候连得上有时候连不上的情况。后来经过一番搜索发现即使用共享网络模式，也需要一些简单的设置。具体步骤如下：</p><ol><li><p>在PD的偏好设置中进行网络设置，添加(+)端口转发规则如下：<img src="./20190216112753690.png" width="60%" alt></p></li><li><p>在虚拟机的网络设置中使用<strong>共享网络</strong>模式<img src="./20190216113314497.png" width="60%" alt></p></li><li><p>重启虚拟机即可</p></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> Mac </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mac上解决访问github慢问题</title>
      <link href="/2019/02/16/Mac%E4%B8%8A%E8%A7%A3%E5%86%B3%E8%AE%BF%E9%97%AEgithub%E6%85%A2%E9%97%AE%E9%A2%98/"/>
      <url>/2019/02/16/Mac%E4%B8%8A%E8%A7%A3%E5%86%B3%E8%AE%BF%E9%97%AEgithub%E6%85%A2%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<ol><li>访问 <a href="http://github.global.ssl.fastly.net.ipaddress.com/#ipinfo" target="_blank" rel="noopener">http://github.global.ssl.fastly.net.ipaddress.com/#ipinfo</a> 获取github的IP地址</li><li>在/etc/hosts中加入查询到的IP和域名 （需要root 权限）</li><li>在终端在输以下指令刷新DNS（需要root 权限）  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo killall -HUP mDNSResponder;say DNS cache has been flushed</span><br></pre></td></tr></table></figure></li></ol><p> 或者也可以参见<a href="https://blog.csdn.net/yolohohohoho/article/details/87647036" target="_blank" rel="noopener">懒人版代码</a></p><p>其他Mac相关问题：<a href="https://blog.csdn.net/yolohohohoho/article/details/87892412" target="_blank" rel="noopener">brew update慢的解决方法</a><a href="https://blog.csdn.net/yolohohohoho/article/details/87893368" target="_blank" rel="noopener">conda install慢的解决方法</a></p>]]></content>
      
      
      <categories>
          
          <category> Mac </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mac </tag>
            
            <tag> github </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>VirtualBox共享MacOS的VPN</title>
      <link href="/2019/02/16/VirtualBox%E5%85%B1%E4%BA%ABMacOS%E7%9A%84VPN/"/>
      <url>/2019/02/16/VirtualBox%E5%85%B1%E4%BA%ABMacOS%E7%9A%84VPN/</url>
      
        <content type="html"><![CDATA[<p>在Mac上装了一个Cloudera的quickstart版本到virtualbox里面发现无法共享主机的VPN，简单搜索了一下，只需要做一些基本的配置就可以了。</p><h4 id="设置主机SS的HTTP-代理"><a href="#设置主机SS的HTTP-代理" class="headerlink" title="设置主机SS的HTTP 代理"></a>设置主机SS的HTTP 代理</h4><p>如图：</p><p><img src="./20190216122645771.png" width="60%" alt></p><h4 id="设置虚拟机网络连接模式"><a href="#设置虚拟机网络连接模式" class="headerlink" title="设置虚拟机网络连接模式"></a>设置虚拟机网络连接模式</h4><p>选择桥接模式,并选择WiFI(Airport).<img src="./20190216122348636.png" width="60%" alt></p><h4 id="设置虚拟机实例网络连接"><a href="#设置虚拟机实例网络连接" class="headerlink" title="设置虚拟机实例网络连接"></a>设置虚拟机实例网络连接</h4><p>首先，查看主机的网络链接信息<img src="./20190216122402569.png" width="60%" alt></p><p>然后进入实例的网络连接设置</p><p>添加并创建网络连接</p><p><img src="./20190216122427601.png" width="60%" alt><img src="./20190216122439284.png" width="60%" alt></p><p>因为选用桥接模式，手动为该实例添加一个和主机在同一范围的IP，并根据主机的TCP/IP信息填写网关，配置如下：<img src="./20190216122450764.png" width="60%" alt>测试在虚拟机中ping主机的内网IP：<img src="./20190216122500875.png" width="60%" alt>然后配置HTTP-PROXY：</p><ul><li>IP为主机内网IP</li><li>端口为之前SS设置的监听端口号</li></ul><p><img src="./20190216122525464.png" width="60%" alt>测试</p><p><img src="./20190216122617322.png" width="60%" alt></p><p><strong>Voilà Voilà</strong></p>]]></content>
      
      
      <categories>
          
          <category> Mac </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mac </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TD笔记 | Teradata数据压缩</title>
      <link href="/2019/02/16/%5BTD%E7%AC%94%E8%AE%B0%5DTeradata%E6%95%B0%E6%8D%AE%E5%8E%8B%E7%BC%A9/"/>
      <url>/2019/02/16/%5BTD%E7%AC%94%E8%AE%B0%5DTeradata%E6%95%B0%E6%8D%AE%E5%8E%8B%E7%BC%A9/</url>
      
        <content type="html"><![CDATA[<p>工作上需要研究Teradata CLOB类型，因为去看了官方文档，自己做了点笔记如下：</p><h3 id="Teradata数据压缩"><a href="#Teradata数据压缩" class="headerlink" title="Teradata数据压缩"></a>Teradata数据压缩</h3><h4 id="概况"><a href="#概况" class="headerlink" title="概况"></a>概况</h4><p>本章描述了几种数据压缩选项，它能够帮助你减少磁盘空间的使用，在某种情况下，还可以提高I/O性能。</p><ul><li>多值压缩（MVC)</li><li>算法压缩（ALC）</li><li>行压缩</li><li>行标题压缩</li><li>自动压缩</li><li>哈希索引和连接索引行压缩</li><li>块级压缩（BLC) </li></ul><p>压缩的目标是利用最少的位数(bits)来准确的表示信息。压缩方法可分为物理方法和逻辑方法。物理方法独立于数据本身意义对其进行重新编码， 而逻辑方法则通过一个更紧凑的集合来替换。</p><p>压缩通过在单位物理容量中存储更多的逻辑数据来降低存储成本。压缩产生更小的行，因此每个可以数据块存储更多行以减少数据块数量。</p><p>压缩还可以提高系统性能，因为每个查询返回更少的物理数据，同时压缩过的数据在内存中保持压缩状态，因此FSG[1]缓存可容纳更多行，从而减少磁盘I/O的大小。</p><p>[1]FSG cache: File Segment cache, a Teradata caching approach.</p><p>算法压缩可以是有损或者是无损的，这取决于所选用的的算法。</p><p>TD的压缩一个很小的初始成本，但是即使对于小表的查询，主要选择的压缩方法能过减小表的大小，这就是一个净赢。</p><h4 id="块级压缩"><a href="#块级压缩" class="headerlink" title="块级压缩"></a>块级压缩</h4><p>数据块是I/O基本物理单位，用于定义TD如何处理数据。当你指定了块级压缩选项，TD将以压缩格式存储数据来减少存储空间。</p><p>BLC可以应用到这几种类型的表：</p><ul><li>主要数据，回退，甚至是无法重新启动的表</li></ul><p>BLC还可以应用于这几种类型的子表：</p><ul><li>BLOB, CLOB, XML, JOIN INDEX, HASH INDEX和Reference index.</li></ul><p>BLC独立应用于其他任何应用于相同数据的压缩类型。BLC可以使用更多的CPU来动态压缩和解压数据，所以查询性能是否随BLC而增强取决于性能是否受I/O带宽或CPU使用率的限制。</p>]]></content>
      
      
      <categories>
          
          <category> DWH </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Teradata </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据仓库笔记 —— 数据仓库架构</title>
      <link href="/2017/12/14/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E6%9E%B6%E6%9E%84/"/>
      <url>/2017/12/14/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E6%9E%B6%E6%9E%84/</url>
      
        <content type="html"><![CDATA[<h4 id="基本架构"><a href="#基本架构" class="headerlink" title="基本架构"></a>基本架构</h4><p>“架构”是什么?这个问题从来就没有一个准确的答案。在软件行业，一种被普遍接受的架构定义是指系统的一个或多个结构。结构中包括软件的构建(构建是指软件的设计与实现)，构建的外部可以看到属性以及它们之间的相互关系。这里参考此定义，把数据仓库架构理解成构成数据仓库的组件及其之间的关系，那么就有了如图1-1 所示的数据仓库架构图。</p><p><img src="./20190527100810521.png" alt></p><p>图中显示的整个数据仓库环境包括操作型系统和数据仓库系统两大部分。操作型系统的数据由各种形式的业务数据组成，这其中可能有关系数据库、TXT或CSV文 件、HTML或XML文档，还可能存在外部系统的数据，比如网络爬虫抓取来的互联网数据等，==数据可能是结构化、半结构化、非结构化的==。这些数据经过==抽取、转换和装载(ETL)过程==进入数据仓库系统。</p><p>这里把ETL过程分成了抽取和转换装载两个部分。==<strong>抽取过程负责从操作型系统获取数据</strong>，<strong>该过程一般不做数据聚合和汇总</strong>==，但是会按照主题进行集成，物理上是将操作型系统的数据<strong>全量</strong>或<strong>增量</strong>复制到数据仓库系统的<strong>RDS</strong>中。==转换装载过程并将数据进行清洗、过滤、汇总、统一格式化等一系列转换操作，使数据转为适合查询的格式， 然后装载进数据仓库系统的<strong>TDS</strong>中==。传统数据仓库的基本模式是用一些过程将操作型系统的数据抽取到文件，然后另一些过程将这些文件转化成MySQL或Oracle这样的关系数据库的记录。最后，第三部分过程负责把数据导入进数据仓库。</p><ul><li>RDS(RAW DATA STORES)是原始数据存储的意思。将原始数据保存到数据仓库里是个不错的想法。ETL过程的bug或系统中的其他错误是不可避免的，保留原始数 据使得追踪并修改这些错误成为可能。有时数据仓库的用户会有查询细节数据的需求，这些细节数据的粒度与操作型系统的相同。有了RDS，这种需求就很容易实现，用 户可以查询RDS里的数据而不必影响业务系统的正常运行。这里的RDS实际上是起到了操作型数据存储(ODS)的作用，关于ODS相关内容本小节后面会有详细论述。</li><li>TDS(TRANSFORMED DATA STORES)意为转换后的数据存储。这是真正的数据仓库中的数据。大量的用户会在经过转换的数据集上处理他们的日常查询。如果前 面的工作做得好，这些数据将被以保证最重要的和最频繁的查询能够快速执行的方式构建。</li><li>这里的原始数据存储和转换后的数据存储是<strong>逻辑概念</strong>，==它们可能物理存储在一起，也可能分开==。当原始数据存储和转换后的数据存储物理上分开时，它们不必使用同样的软硬件。传统数据仓库中，原始数据存储通常是本地文件系统，原始数据被组织进相应的目录中，这些目录是基于数据从哪里抽取或何时抽取建立(例如以日期作为文件或目录名称的一部分); 转换后的数据存储一般是某种关系数据库。</li></ul><p><strong>自动化调度组件</strong>的作用是自动定期重复执行ETL过程。不同角色的数据仓库用户对数据的更新频率要求也会有所不同，财务主管需要每月的营收汇总报告，而销售人员想看到每天的产品销售数据。作为通用的需求，所有数据仓库系统都应该能够建立周期性自动执行的工作流作业。传统数据仓库一般利用操作系统自带的调度功能(如 Linux的cron或Windows的计划任务)实现作业自动执行。</p><p><strong>数据目录</strong>有时也被称为<strong>元数据存储</strong>，它可以提供一份数据仓库中数据的清单。用户通过它应该可以快速解决这些问题:</p><ul><li>什么类型的数据被存储在哪里</li><li>数据集的构建有何区别</li><li>数据最后的访问或更新时间等。</li></ul><p>此外还可以通过数据目录感知数据是如何被操作和转换的。==一个好的数据目录是让用户体验到系统易用性的关键==。查询引擎组件负责实际执行用户查询。传统数据仓库中，它可能是存储转换后数据的(Oracle、MySQL等关系数据库系统内置的)查询引擎，还可能是以固定时间间隔向其导入数据的OLAP立方体，如Essbase cube。用户界面指的是最终用户所使用的接口程序。可能是一个GUI软件，如BI套件的中的客户端软件，也可能就是一个浏览器</p><h4 id="主要数据仓库架构"><a href="#主要数据仓库架构" class="headerlink" title="主要数据仓库架构"></a>主要数据仓库架构</h4><p>在数据仓库技术演化过程中，产生了几种主要的架构方法，包括数据集市架构、Inmon企业信息工厂架构、Kimball数据仓库架构和混合型数据仓库架构。</p><h5 id="1-数据集市架构"><a href="#1-数据集市架构" class="headerlink" title="1. 数据集市架构"></a>1. 数据集市架构</h5><p>==数据集市是<strong>按主题域</strong>组织的数据集合==，用于支持部门级的决策。有两种类型的数据集市:独立数据集市和从属数据集市。</p><p>独立数据集市集中于部门所关心的单一主题域，数据以部门为基础部署，无须考虑企业级别的信息共享与集成。例如，制造部门、人力资源部门和其他部门都各自有 他们自己的数据集市。独立数据集市从一个主题域或一个部门的多个事务系统获取数据，用以支持特定部门的业务分析需要。一个独立数据集市的设计既可以使用实体关 系模型，也可以使用多维模型。数据分析或商业智能工具直接从数据集市查询数据，并将查询结果显示给用户。一个典型的独立数据集市架构如图1-2所示。</p><p>因为一个部门的业务相对于整个企业要简单，数据量也小得多，所以部门的独立数据集市具有周期短、见效快的特点。如果从企业整体的视角来观察这些数据集市， 你会看到每个部门使用不同的技术，建立不同的ETL的过程，处理不同的事务系统，而在多个独立的数据集市之间还会存在数据的交叉与重叠，甚至会有数据不一致的情 况。从业务角度看，当部门的分析需求扩展，或者需要分析跨部门或跨主题域的数据时，独立数据市场会显得力不从心。而当数据存在歧义，比如同一个产品，在A部门 和B部门的定义不同时，将无法在部门间进行信息比较。</p><p><img src="./20190527101600206.png" alt></p><p>另外一种数据集市是从属数据集市。如Bill Inmon所说，从属数据集市的数据来源于数据仓库。==数据仓库里的数据经过整合、重构、汇总后传递给从属数据集市==。从属数据集市的架构如图1-3所示。<img src="./20190527101725230.png" alt></p><p>建立从属数据集市的好处主要有:</p><ul><li><strong>性能</strong>:当数据仓库的查询性能出现问题，可以考虑建立几个从属数据集市，将查询从数据仓库移出到数据集市。 </li><li><strong>安全</strong>:每个部门可以完全控制他们自己的数据。 </li><li><strong>数据一致</strong>:因为每个数据集市的数据来源都是同一个数据仓库，有效消除了数据不一致的情况。</li></ul><p>Inmon企业信息工厂架构Inmon企业信息工厂架构如图1-4所示，我们来看图中的组件是如何协同工作的。<img src="./20190527102102113.png" alt></p><ul><li><strong>应用系统</strong>: 这些应用是组织中的操作型系统，用来支撑业务。它们收集业务处理过程中产生的销售、市场、材料、物流等数据，并将数据以多种形式进行存储。操作型系统也叫源系统，为数据仓库提供数据。 </li><li><strong>ETL过程</strong>: ETL过程从操作型系统抽取数据，然后将数据转换成一种标准形式，最终将转换后的数据装载到企业级数据仓库中。ETL是周期性运行的批处理过程。 </li><li><strong>企业级数据仓库</strong>: 是该架构中的核心组件。正如Inmon数据仓库所定义的，企业级数据仓库是一个细节数据的集成资源库。其中的数据以最低粒度级别被捕获，存储在满足三范式设计的关系数据库中。 </li><li><strong>部门级数据集市:</strong> 是面向主题数据的部门级视图，数据从企业级数据仓库获取。数据在进入部门数据集市时可能进行聚合。数据集市使用多维模型设计，用于数据 分析。重要的一点是，所有的报表工具、BI工具或其他数据分析应用都从数据集市查询数据，而不是直接查询企业级数据仓库。</li></ul><h5 id="2-Kimball数据仓库架构"><a href="#2-Kimball数据仓库架构" class="headerlink" title="2. Kimball数据仓库架构"></a>2. Kimball数据仓库架构</h5><p>Kimball数据仓库架构如图1-5所示。<img src="./20190527101846515.png" alt></p><p>对比上一张图可以看到，==Kimball与Inmon两种架构的主要区别在于核心数据仓库的设计和建立==。Kimball的数据仓库<strong>包含高粒度</strong>的企业数据，使用多维模型设计，==这也意味着数据仓库由星型模式的维度表和事实表构成==。分析系统或报表工具可以直接访问多维数据仓库里的数据。在此架构中的数据集市也与Inmon中的不同。==这里的数据集市是一个逻辑概念，只是多维数据仓库中的主题域划分，并没有自己的物理存储，也可以说是虚拟的数据集市==。</p><h5 id="3-混合型数据仓库架构"><a href="#3-混合型数据仓库架构" class="headerlink" title="3. 混合型数据仓库架构"></a>3. 混合型数据仓库架构</h5><p>混合型数据仓库架构如图1-6所示。<img src="./20190527102345389.png" alt></p><p>所谓的混合型结构，指的是在一个数据仓库环境中，联合使用Inmon和Kimball两种架构。从架构图可以看到，这种架构将Inmon方法中的数据集市部分替换成了一个多维数据仓库，而数据集市则是多维数据仓库上的逻辑视图。使用这种架构的好处是，==既可以利用规范化设计消除数据冗余，保证数据的粒度足够细;又可以利用多维结构 更灵活地在企业级实现报表和分析==。</p><h4 id="操作数据存储"><a href="#操作数据存储" class="headerlink" title="操作数据存储"></a>操作数据存储</h4><p>操作数据存储又称为<strong>ODS</strong>，是Operational Data Store的简写，其定义是这样的: ==一个面向主题的、集成的、可变的、当前的细节数据集合，用于支持企业对于即时性的、操作性的、集成的全体信息的需求==。对比1.1节中数据仓库的定义不难看出，操作型数据存储在某些方面具有类似于数据仓库的特点，但在另一些方面又显著不同于数据仓库。</p><ul><li>像数据仓库一样，是面向主题的。</li><li>像数据仓库一样，其数据是完全集成的。 </li><li>数据是当前的，这与数据仓库存储历史数据的性质明显不同。ODS具有最少的历史数据(一般是30天到60天)，而尽可能接近实时地展示数据的状态。 </li><li>数据是可更新的，这是与静态数据仓库又一个很大的区别。ODS就如同一个事务处理系统，当新的数据流进ODS时，受其影响的字段被新信息覆盖。 </li><li>数据几乎完全是细节数据，仅具有少量的动态聚集或汇总数据。通常将ODS设计成包含事务级的数据，即包含该主题域中最低粒度级别的数据。 </li><li>在数据仓库中，几乎没有针对其本身的报表，报表均放到数据集市中完成;与此不同，在ODS中，业务用户频繁地直接访问ODS。</li></ul><p>在一个数据仓库环境中，ODS具有如下几个作用:</p><ul><li>==充当<strong>业务系统</strong>与<strong>数据仓库</strong>之间的<strong>过渡区</strong>==。数据仓库的数据来源复杂，可能分布在不同的数据库，不同的地理位置，不同的应用系统之中，而且由于数据形式的多样 性，数据转换的规则往往极为复杂。如果直接从业务系统抽取数据并做转换，不可避免地会对业务系统造成影响。而ODS中存放的数据从数据结构、数据粒度、数据之间的逻辑关系上都与业务系统基本保持一致，因此抽取过程只需简单的数据复制而基本不再需要做数据转换，大大降低了复杂性，同时最小化对业务系统的侵 入。</li><li>转移部分业务系统细节查询的功能。==某些原来由业务系统产生的报表、细节数据的查询能够在ODS中进行，从而降低业务系统的查询压力==。 </li><li>完成数据仓库中不能完成的一些功能。用户有时会要求数据仓库查询最低粒度级别的细节数据，而数据仓库中存储的数据一般都是聚合或汇总过的数据，并不存储每笔交易产生的细节数据。这时就需要把细节数据查询的功能转移到ODS来完成，而且ODS的数据模型是按照面向主题的方式组织的，可以方便地支持多维分析。 ==即数据仓库从宏观角度满足企业的决策支持要求，而ODS层则从微观角度反映细节交易数据或者低粒度的数据查询要求。==</li></ul><h4 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h4><p>[Book]Hadoop构建数据仓库实践, 第1章第3节 —— 操作型系统与分析型系统</p>]]></content>
      
      
      <categories>
          
          <category> DWH </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DWH </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据仓库笔记 —— 操作型系统与分析型系统</title>
      <link href="/2017/12/13/%E6%93%8D%E4%BD%9C%E5%9E%8B%E7%B3%BB%E7%BB%9F%E4%B8%8E%E5%88%86%E6%9E%90%E5%9E%8B%E7%B3%BB%E7%BB%9F/"/>
      <url>/2017/12/13/%E6%93%8D%E4%BD%9C%E5%9E%8B%E7%B3%BB%E7%BB%9F%E4%B8%8E%E5%88%86%E6%9E%90%E5%9E%8B%E7%B3%BB%E7%BB%9F/</url>
      
        <content type="html"><![CDATA[<h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><ul><li><strong>操作型系统</strong>完成组织的核心业务，例如下订单、更新库存、记录支付信息等。这些系统是事务型的，核心目标是尽可能快地处理事务，同时维护数据的一致性和完整性。</li><li><strong>分析型系统</strong>的主要作用是通过数据分析评估组织的业务经营状况，并进一步辅助决策。</li></ul><h4 id="操作型系统"><a href="#操作型系统" class="headerlink" title="操作型系统"></a>操作型系统</h4><h5 id="操作型系统的特性"><a href="#操作型系统的特性" class="headerlink" title="操作型系统的特性"></a>操作型系统的特性</h5><p>操作型系统是一类专门用于管理<strong>面向事务</strong>的应用的信息系统。</p><p>事务是工作于数据库管理系统(或类似系统)中的一个逻辑单元，该逻辑单元中的操作被以一种独立于其他事务的可靠方式所处理。==事务一般代表着数据改变==，它提 供“<strong>all-or-nothing</strong>”操作，就是说事务中的一系列操作要么完全执行，要么完全不执行。在数据库中使用事务主要出于两个目的:</p><ol><li>保证工作单元的可靠性。当数据库系统异常宕机时，其中执行的操作或者已经完成或者只有部分完成，很多没有完成的操作此时处于一种模糊状态。在这种情况 下，数据库系统必须能够恢复到数据一致的正常状态。</li><li>提供并发访问数据库的多个程序间的隔离。如果没有这种隔离，程序得到的结果很可能是错误的。</li></ol><blockquote><p>根据事务的定义，引申出事务具有<strong>原子性、一致性、隔离性、持久性</strong>的特点，也就是数据库领域中常说的事务的<strong>ACID</strong>特性。</p></blockquote><ul><li><p><strong>原子性</strong>指的是事务中的==一系列操作<strong>或全执行或不执行</strong>==，这些操作是不可再分的。==<strong>原子性可以防止数据被部分修改</strong>==。银行账号间转账是一个事务原子性的例子。简单地说，从 A账号向B账号转账有两步操作:A账号提取，B账号存入。这两个操作以原子性事务执行，使数据库保持一致的状态，即使这两个操作的任何一步失败了，总的金额数不 会减少也不会增加。</p></li><li><p><strong>一致性</strong>数据库系统中的一致性是指任何数据库事务只能以允许的方式修改数据。任何数据库写操作必须遵循既有的规则，包括约束、级联、触发器以及它们的任意组合。一致性并不保证应用程序逻辑的正确性，但它能够保证不会因为程序错误而使数据库产生违反规则的结果</p></li><li><p><strong>隔离性</strong>在数据库系统中，隔离性决定了其他用户所能看到的事务完整性程度。例如，一个用户正在生成一个采购订单，并且已经生成了订单主记录，但还没有生成订单条目 明细记录。此时订单主记录能否被其他并发用户看到呢? 这就是由隔离级别决定的。数据库系统中，按照由低到高一般有<strong>读非提交、读提交、可重复读、串行化</strong>等几种隔 离级。数据库系统并不一定实现所有的隔离级别，如Oracle数据库只实现了读提交和串行化，而MySQL数据库则提供这全部四种隔离级别。</p><blockquote><p>隔离级越低，多用户同时访问数据的能力越高，但同时也会增加<strong>脏读、丢失更新等并发</strong>操作的负面影响。相反，高隔离级降低了并发影响，但需要使用更多的系统资源，也增加了事务被阻塞的可能性。</p></blockquote></li><li><p><strong>持久性</strong>数据库系统的持久性保证已经提交的事务是永久保存的。例如，如果一个机票预订报告显示一个座位已经订出，那么即使系统崩溃，被订了的座位也会一直保持被订出的状态。持久性可以通过在事务提交时将事务日志刷新至永久性存储介质来实现。</p></li></ul><p><strong>操作型系统</strong>通常是<strong>高并发、高吞吐量</strong>的系统，具有<strong>大量检索、插入、更新操作</strong>，事务数量大， 但每个事务影响的数据量相对较小。这样的系统很适合在线应用，这些应用有成千上万用户在同时使用，并要求能够立即响应用户请求。操作型系统常被整合到面向服务的架构(SOA)和Web服务里。对操作型系统应用的主要要求是高可用、高速度、高并发、可恢复和保证数据一致性，在各种互联网应用层出不穷的今天，这些系统要求 是显而易见的。</p><h5 id="1-操作型系统的数据库操作"><a href="#1-操作型系统的数据库操作" class="headerlink" title="1. 操作型系统的数据库操作"></a>1. 操作型系统的数据库操作</h5><p>在数据库使用上，操作型系统常用的操作是增、改、查，并且通常是插入与更新密集型的，同时会对数据库进行大量并发查询，而删除操作相对较少。==操作型系统一般都直接在数据库上修改数据，没有中间过渡区==。 </p><h5 id="2-操作型系统的数据库设计"><a href="#2-操作型系统的数据库设计" class="headerlink" title="2.操作型系统的数据库设计"></a>2.操作型系统的数据库设计</h5><p>==<strong>操作型系统的特征是大量短的事务，并强调快速处理查询</strong>==。每秒事务数是操作型系统的一个有效度量指标。针对以上这些特点，数据库设计一定要满足系统的要求。</p><p> 在数据库逻辑设计上，操作型系统的应用数据库大都使用规范化设计方法，<strong>通常要满足第三范式</strong>。这是因为规范化设计能最大限度地数据冗余，因而提供更快更高效的方式执行数据库写操作。</p><p>在数据库物理设计上，应该依据系统所使用的数据库管理系统的具体特点，做出相应的设计，毕竟每种数据库管理系统在实现细节上还是存在很大差异的。下面就以Oracle数据库为例，简要说明在设计操作型系统数据库时应该考虑的问题。</p><ul><li>调整回滚段。回滚段是数据库的一部分，其中记录着最终被回滚的事务的行为。这些回滚段信息可以提供读一致性、回滚事务和数据库恢复。 </li><li>合理使用聚簇。聚簇是一种数据库模式，其中包含有共用一列或多列的多个表。数据库中的聚簇表用于提高连接操作的性能。 </li><li>适当调整数据块大小。数据块大小应该是操作系统块大小的倍数，并且设置上限以避免不必要的I/O。 </li><li>设置缓冲区高速缓存大小。合理的缓存大小能够有效避免不必要的磁盘I/O。</li><li>动态分配表空间。 </li><li>合理划分数据库分区。分区最大的作用是能在可用性和安全性维护期间保持事务处理的性能。 </li><li>SQL优化。有效利用数据库管理系统的优化器，使用最佳的数据访问路径。 </li><li>避免过度使用索引。大量的数据修改会给索引维护带来压力，从而对整个系统的性能产生负面影响。</li></ul><p>==以上所讲的操作型系统都是以数据库系统为核心，而数据库系统为了保持<strong>ACID</strong>特性，本质上是单一集中式系统==。在当今这个信息爆炸的时代，集中式数据库往往已无法支撑业务的需要(从某订票网站和某电商网站的超大瞬时并发量来看，这已是一个不争的事实)。这就给操作型系统带来新的挑战。<strong>分布式事务、去中心化、CAP与最终一致性</strong>等一系列新的理论和技术为解决系统扩展问题应运而生。</p><h4 id="分析型系统"><a href="#分析型系统" class="headerlink" title="分析型系统"></a>分析型系统</h4><p>在计算机领域，分析型系统是 ==<strong>一种快速回答多维分析查询的实现方式</strong>==。它也是更广泛范畴的所谓<strong>商业智能</strong>的一部分(商业智能还包含数据库、报表系统、数据挖掘、数据可视化等研究方向)。分析型系统的典型应用包括销售业务分析报告、市场管理报告、业务过程管理(BPM)、预算和预测、金融分析报告及其类似的应用。</p><h5 id="1-分析型系统的数据库操作"><a href="#1-分析型系统的数据库操作" class="headerlink" title="1.分析型系统的数据库操作"></a>1.分析型系统的数据库操作</h5><p>在数据库层面，分析型系统操作被定义成==少量的事务，复杂的查询，处理归档和历史数据==。这些数据很少被修改，从数据库抽取数据是最多的操作，也是识别这种系 统的关键特征。分析型数据库基本上都是读操作。</p><h5 id="2-分析型系统的数据库设计"><a href="#2-分析型系统的数据库设计" class="headerlink" title="2.分析型系统的数据库设计"></a>2.分析型系统的数据库设计</h5><p>分析型系统的特征是==相对少量的事务，但查询通常<strong>非常复杂</strong>并且会包含聚合计算==，例如今年和去年同时期的数据对比、百分比变化趋势等。分析型数据库中的数据一般来自于一个<strong>企业级数据仓库</strong>，是整合过的历史数据。对于分析型系统，吞吐量是一个有效的性能度量指标。</p><p>在数据库逻辑设计上，分析型数据库使用<strong>多维数据模型</strong>，==通常是设计成星型模式或雪花模式==。</p><p>在数据库物理设计上，依然以Oracle数据库为例，简要说明在设计分析型系统数据库时应该考虑的一些问题。</p><ul><li>表分区。可以独立定义表分区的物理存储属性，将不同分区的数据存放到多个物理文件上，这样做一方面可以分散I/O;另一方面，当数据量非常大时，方便数据 维护;再有就是利用分区消除查询数据时，不用扫描整张表，从而提高查询性能。 </li><li>位图索引。当查询条件中包含低基数(不同值很少，例如性别)的列，尤其是包含有这些列上的or、and或not这样的逻辑运算时，或者从有大量行的表中返回大量 的行时，应考虑位图索引。 </li><li>物化视图。物化视图物理存储查询所定义的数据，能够自动增量刷新数据，并且可以利用查询重写特性极大地提高查询速度，是分析型系统常用的技术。 </li><li>并行化操作。可以在查询大量数据时执行并行化操作，这样会导致多个服务器进程为同一个查询语句工作，使用该查询可以快速完成，但是会耗费更多的资源。</li></ul><h4 id="操作型系统和分析型系统对比"><a href="#操作型系统和分析型系统对比" class="headerlink" title="操作型系统和分析型系统对比"></a>操作型系统和分析型系统对比</h4><p><img src="./20190526224455389.png" alt></p><ul><li>首先两种系统的侧重点不同。操作型系统更适合对已有数据的更新，所以是日常处理工作或在线系统的选择。相反，分析型系统提供在大量存储数据上的分析能力， 所以这类系统更适合报表类应用。分析型系统通常是查询历史数据，这有助于得到更准确的分析报告。</li><li>其次因为这两种系统的目标完全不同，所以为了得到更好的性能，使用的数据模型和设计方法也不同。操作型系统数据库通常使用规范化设计，为普通查询和数据修 改提供更好的性能。另一方面，分析型数据库具有典型的数据仓库组织形式。</li><li>基于这两个主要的不同点，我们可以推导出两种系统其他方面的区别。操作型系统上的查询更小，而分析型系统上执行的查询要复杂得多。所以操作型系统会比分析 型系统快很多。</li><li>操作型系统的数据会持续更新，并且更新会立即生效。而分析型系统的数据更新，是由预定义的处理作业同时装载大量的数据集合，并且在装载前需要做数据转换， 因此整个数据更新过程需要很长的执行时间。</li><li>由于操作型系统要做到绝对的数据安全和可用性，所以需要实施复杂的备份系统。基本的全量备份和增量备份都是必须要做的。而分析型系统只需要偶尔执行数据备 份即可，这一方面是因为这类系统一般不需要保持持续运行，另一方面数据还可以从操作型系统重复装载。两种系统的空间需求显然都依赖于它们所存储的数据量。分析型系统要存储大量的历史数据，因此需要更多的存储空间。</li></ul><h4 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h4><p>[Book]Hadoop构建数据仓库实践, 第一章第二节 —— 操作型系统与分析型系统</p>]]></content>
      
      
      <categories>
          
          <category> DWH </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DWH </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据仓库笔记 —— 什么是数据仓库</title>
      <link href="/2017/12/12/%E4%BB%80%E4%B9%88%E6%98%AF%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/"/>
      <url>/2017/12/12/%E4%BB%80%E4%B9%88%E6%98%AF%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/</url>
      
        <content type="html"><![CDATA[<h3 id="什么是数据仓库"><a href="#什么是数据仓库" class="headerlink" title="什么是数据仓库"></a>什么是数据仓库</h3><p>本质上，数据仓库试图提供一种从操作型系统到决策支持环境的数据流架构模型。数据仓库概念的提出，是为了解决和这个数据流相关的各种问题，主要是解决多重数据复制带来的高成本问题。</p><h4 id="数据仓库的定义"><a href="#数据仓库的定义" class="headerlink" title="数据仓库的定义"></a>数据仓库的定义</h4><p>数据仓库之父Bill Inmon在1991年出版的Building the Data Warehouse 一书中首次提出了被广为认可的数据仓库定义。Inmon将数据仓库描述为一个<strong>面向主题的、集成的、随时间变化的、非易失的数据集合</strong>，用于<strong>支持管理者的决策过程</strong>。</p><ul><li><strong>面向主题</strong>传统的操作型系统是围绕组织的功能性应用进行组织的，而数据仓库是面向主题的。主题是一个抽象概念，简单地说就是<strong>与业务相关的数据的类别</strong>，每一个主题基本 对应一个宏观的分析领域。数据仓库被设计成辅助人们分析数据。例如，一个公司要分析销售数据，就可以建立一个专注于销售的数据仓库，使用这个数据仓库，就可以回答类似于“去年谁是我们这款产品的最佳用户”这样的问题。这个场景下的销售，就是一个数据主题，而这种通过划分主题定义数据仓库的能力，就使得数据仓库是面向 主题的。主题域是对某个主题进行分析后确定的主题的边界，如客户、销售、产品都是主题域的例子</li><li><strong>集成</strong>集成的概念与面向主题是密切相关的。还用销售的例子，假设公司有多条产品线和多种产品销售渠道，而每个产品线都有自己独立的销售数据库。此时要想从公司层面整体分析销售数据，==必须将多个分散的数据源统一成一致的、无歧义的数据格式后，再放置到数据仓库中==。因此数据仓库必须能够解决诸如产品命名冲突、计量单位不一致等问题。当完成了这些数据整合工作后，该数据仓库就可称为是集成的。</li><li><strong>随时间变化</strong>为了发现业务变化的趋势、存在的问题，或者新的机会，需要分析大量的历史数据。这与联机事务处理(OLTP)系统形成鲜明的对比。联机事务处理反应的是当前时间点的数据情况，要求高性能、高并发和极短的响应时间，出于这样的需求考虑，联机事务处理系统中一般都将数据依照活跃程度分级，把历史数据迁移到归档数据库 中。而数据仓库关注的是数据随时间变化的情况，并且能反映在过去某个时间点的数据是怎样的。换句话说，数据仓库中的数据是 ==<strong>反映了某一历史时间点的数据快照</strong>==，这也就是术语“随时间变化”的含义。当然，任何一个存储结构都不可能无限扩展，数据也不可能只入不出地永久驻留在数据仓库中，==它在数据仓库中也有自己的生命周期。到了一定时候，数据会从数据仓库中移除。移除的方式可能是将细节数据汇总后删除、将老的数据转储到大容量介质后删除和直接物理删除等==。</li><li><p><strong>非易失</strong>非易失指的是，一旦进入到数据仓库中，数据就不应该再有改变。==操作型环境中的数据一般都会频繁更新，而在数据仓库环境中一般并不进行数据更新==。当改变的操作型数据进入数据仓库时会产生新的记录，这样就保留了数据变化的历史轨迹。也就是说，==数据仓库中的数据基本是静态的==。这是一个不难理解的逻辑概念。数据仓库的目的就是要根据曾经发生的事件进行分析，如果数据是可修改的，将使历史分析变得没有意义。</p></li><li><p><strong>粒度</strong>数据仓库还有一个非常重要的概念就是<strong>粒度</strong>。粒度问题遍布于数据仓库体系结构的各个部分。粒度是指数据的细节或汇总程度，细节程度越高，粒度级别越低。例如，单个事务是低粒度级别，而全部一个月事务的汇总就是高粒度级别。数据粒度一直是数据仓库设计需要重点思考的问题。在早期的操作型系统中，当细节数据被更新时，几乎总是将其存放在最低粒度级别上;而在数据仓库环境中，通常都不这样做。==例如，如果数据被装载进数据仓库的频率是每天一次，那么一天之内的数据更新将被忽略==。粒度之所以是数据仓库环境的关键设计问题，是因为它极大地影响数据仓库的数据量和可以进行的查询类型。==粒度级别越低，数据量越大，查询的细节程度越高，查 询范围越广泛，反之亦然==。==大多数情况下，数据会以很低的粒度级别进入数据仓库，如日志类型的数据或单击流数据，此时应该对数据进行编辑、过滤和汇总，使其适应数据仓库环境的粒度级别==。如果得到的数据粒度级别比数据仓库的高，那将意味着在数据存入数据仓库前，开发人员必须花费大量设计和资源来对数据进行拆分。</p></li></ul><h4 id="建立数据仓库的原因"><a href="#建立数据仓库的原因" class="headerlink" title="建立数据仓库的原因"></a>建立数据仓库的原因</h4><p>现在你应该已经熟悉了数据仓库的概念，那么数据仓库里的数据从哪里来呢?通常数据仓库的数据来自各个业务应用系统。业务系统中的数据形式多种多样，可能是:</p><ul><li>Oracle、MySQL、SQL Server等关系数据库里的<strong>结构化数据</strong>，</li><li>可能是文本、CSV等<strong>平面文件</strong></li><li>Word、Excel文档中的<strong>非结构化数据</strong>，</li><li>还可能是HTML、XML等自描述的<strong>半结构化数据</strong>。这些业务数据经过一系列的<strong>数据抽取、转换、清洗</strong>，最终以一种统一的格式装载进数据仓库。数据仓库里的数据作为分析用的数据源，提供给后面的即席查询、 分析系统、数据集市、报表系统、数据挖掘系统等。</li></ul><p>从以上描述可以看到，从存储的角度看，数据仓库里的数据实际上已经存在于业务应用系统中，那么为什么不能直接操作业务系统中的数据用于分析，而要使用数据仓库呢?实际上在数据仓库技术出现前，有很多数据分析的先驱者已经发现，简单的“直接访问”方式很难良好工作，这样做的失败案例数不胜数。</p><p>下面列举一些直接访问业务系统无法工作的原因:</p><ul><li>某些业务数据由于安全或其他因素不能直接访问。 </li><li>业务系统的版本变更很频繁，每次变更都需要重写分析系统并重新测试。 </li><li>很难建立和维护汇总数据来源于多个业务系统版本的报表。 </li><li>业务系统的列名通常是硬编码，有时仅仅是无意义的字符串，这让编写分析系统更加困难。 </li><li>业务系统的数据格式，如日期、数字的格式不统一。 </li><li>业务系统的表结构为事务处理性能而优化，有时并不适合查询与分析。 </li><li>没有适当的方式将有价值的数据合并进特定应用的数据库。</li><li>没有适当的位置存储元数据。</li><li>用户需要看到的显示数据字段，有时在数据库中并不存在。 </li><li>通常事务处理的优先级比分析系统高，所以如果分析系统和事务处理运行在同一硬件之上，分析系统往往性能很差。 </li><li>有误用业务数据的风险。</li><li>极有可能影响业务系统的性能。</li></ul><p>==在辅助战略决策层面，数据仓库的重要性更加凸显。==</p><p>下面简单总结一下使用数据仓库的好处:</p><ul><li>将多个数据源集成到单一数据存储，因此可以使用单一数据查询引擎展示数据。 </li><li>缓解在事务处理数据库上因执行大查询而产生的资源竞争问题。 </li><li>维护历史数据。 通过对多个源系统的数据整合，使得在整个企业的角度存在统一的中心视图。 </li><li>通过提供一致的编码和描述，减少或修正坏数据问题，提高数据质量。 </li><li>一致性地表示组织信息。 </li><li>提供所有数据的单一通用数据模型，而不用关心数据源。 </li><li>重构数据，使数据对业务用户更有意义。 </li><li>向复杂分析查询交付优秀的查询性能，同时不影响操作型系统。 </li><li>开发决策型查询更简单。<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3>[Book]Hadoop构建数据仓库实践, 第一章第一节 —— 什么是数据仓库</li></ul>]]></content>
      
      
      <categories>
          
          <category> DWH </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DWH </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
